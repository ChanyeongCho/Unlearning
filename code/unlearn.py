# unlearn.py

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset
import copy
import numpy as np
from torch.utils.data import Dataset
from models import ResNet18
import torchvision.utils as utils

# -------------------- UNGAN Generator í•™ìŠµ --------------------
def train_generator_ungan(generator, discriminator, dataset, retain_idxs, forget_idxs, device,
                          lambda_adv=1.0, z_dim=100, batch_size=64, epochs=10):
    """
    ë‹¨ìˆœ adversarial loss ê¸°ë°˜ UNGAN Generator í•™ìŠµ (KL ì œê±°)
    """
    g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)
    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)

    print(f"[UNGAN] Training Generator (adversarial only) for {epochs} epochs...")

    generator.train()
    for epoch in range(epochs):
        for _ in range(len(forget_idxs) // batch_size):
            z = torch.randn((batch_size, z_dim), device=device)
            gen_imgs = generator(z)

            # Adversarial loss: log(D(G(z))) â†’ Gê°€ Dë¥¼ ì†ì´ë„ë¡ ìœ ë„
            d_preds = discriminator(gen_imgs)
            adv_loss = -torch.mean(torch.log(d_preds + 1e-8))

            g_optimizer.zero_grad()
            adv_loss.backward()
            g_optimizer.step()

    print("[UNGAN] Generator training completed.\n")
    return generator

# def train_gd_ungan(generator, discriminator, dataset, retain_idxs, forget_idxs, device,
#                           lambda_adv=1.0, z_dim=100, batch_size=64, epochs=10):
#     """
#     UNGAN Generator & Discriminators ë™ì‹œ í•™ìŠµ (adversarial loss í¬í•¨)
#     """
#     g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)
#     d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)
#     criterion = nn.BCELoss()  # Binary cross entropy loss (GANì—ì„œ ì£¼ë¡œ ì‚¬ìš©)

#     # Forget ë°ì´í„°ì…‹ì˜ ì‹¤ì œ ì´ë¯¸ì§€ë“¤ì„ ìœ„í•œ DataLoader ì¤€ë¹„
#     forget_subset = torch.utils.data.Subset(dataset, forget_idxs)
#     forget_loader = torch.utils.data.DataLoader(forget_subset, batch_size=batch_size, shuffle=True, drop_last=True)

#     print(f"[UNGAN] Training Generator and Discriminator for {epochs} epochs...")

#     generator.train()
#     discriminator.train()

#     for epoch in range(epochs):
#         for real_imgs, _ in forget_loader:
#             real_imgs = real_imgs.to(device)

#             # ---------------------
#             # 1. Discriminator í•™ìŠµ
#             # ---------------------
#             d_optimizer.zero_grad()

#             # ì§„ì§œ ì´ë¯¸ì§€ì— ëŒ€í•´ 1ë¡œ ë ˆì´ë¸” ì§€ì •
#             real_labels = torch.ones((real_imgs.size(0), 1), device=device)
#             # ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•´ 0ìœ¼ë¡œ ë ˆì´ë¸” ì§€ì •
#             fake_labels = torch.zeros((real_imgs.size(0), 1), device=device)

#             # Discriminatorê°€ ì§„ì§œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì˜ ë§ì¶”ë„ë¡
#             real_preds = discriminator(real_imgs)
#             d_loss_real = criterion(real_preds, real_labels)

#             # ê°€ì§œ ì´ë¯¸ì§€ ìƒì„±
#             z = torch.randn((real_imgs.size(0), z_dim), device=device)
#             fake_imgs = generator(z)

#             # Discriminatorê°€ ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì˜ ë§ì¶”ë„ë¡
#             fake_preds = discriminator(fake_imgs.detach())  # detachë¡œ Gì˜ ê·¸ë˜í”„ ë¶„ë¦¬
#             d_loss_fake = criterion(fake_preds, fake_labels)

#             # Discriminator ì „ì²´ ì†ì‹¤ ë° ì—­ì „íŒŒ
#             d_loss = d_loss_real + d_loss_fake
#             d_loss.backward()
#             d_optimizer.step()

#             # ---------------------
#             # 2. Generator í•™ìŠµ
#             # ---------------------
#             g_optimizer.zero_grad()

#             # GeneratorëŠ” Discriminatorë¥¼ ì†ì—¬ì•¼ í•˜ë¯€ë¡œ ì§„ì§œ(1) ë ˆì´ë¸”ë¡œ í•™ìŠµ
#             fake_preds = discriminator(fake_imgs)
#             g_loss = criterion(fake_preds, real_labels)

#             g_loss.backward()
#             g_optimizer.step()

#         print(f"[UNGAN] Epoch {epoch+1}/{epochs} | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}")

#     print("[UNGAN] Generator and Discriminator training completed.\n")
#     return generator, discriminator


# ========== 1. ê¸°ì¡´ train_gd_ungan í•¨ìˆ˜ë¥¼ ì´ê²ƒìœ¼ë¡œ êµì²´ ==========
def train_gd_ungan(generator, discriminator, dataset, retain_idxs, forget_idxs, device,
                   lambda_adv=1.0, z_dim=100, batch_size=64, epochs=10):
    """
    32Ã—32 CIFAR-10ìš©ìœ¼ë¡œ ìµœì í™”ëœ DCGAN í›ˆë ¨ í•¨ìˆ˜
    """
    import torch
    import torch.nn as nn
    import torchvision.utils as utils
    
    # ========== í•˜ì´í¼íŒŒë¼ë¯¸í„° ==========
    niter = epochs
    batch_size = 128  # ë” ì•ˆì •ì ì¸ í›ˆë ¨ì„ ìœ„í•´ ìœ ì§€
    lr = 0.0002
    b1 = 0.5
    b2 = 0.999
    nz = z_dim
    
    # ========== ë°ì´í„°ë¡œë” ì„¤ì • ==========
    # retain ë°ì´í„° ì‚¬ìš© (ì–¸ëŸ¬ë‹ ëª©ì )
    retain_subset = torch.utils.data.Subset(dataset, retain_idxs)
    dataloader = torch.utils.data.DataLoader(retain_subset, batch_size=batch_size, 
                                            shuffle=True, drop_last=True)
    print(f"[DCGAN] Using retain subset: {len(retain_subset)} samples")

    # ========== ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ==========
    criterion = nn.BCELoss()
    optimizerD = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))
    optimizerG = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))
    
    # ========== ê³ ì • ë…¸ì´ì¦ˆ ë° ë¼ë²¨ ==========
    fixed_noise = torch.randn(64, nz, 1, 1, device=device)  # ì‹œê°í™”ìš©
    real_label = 1
    fake_label = 0
    
    # ========== í›ˆë ¨ ê¸°ë¡ìš© ==========
    img_list = []
    g_loss = []
    d_loss = []
    
    print(f"[DCGAN] Starting training for {niter} epochs with {len(dataloader)} batches per epoch")
    
    generator.train()
    discriminator.train()
    
    # ========== í›ˆë ¨ ë£¨í”„ ==========
    for epoch in range(niter):
        for i, data in enumerate(dataloader, 0):
            ############################
            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
            ###########################
            # train with real
            discriminator.zero_grad()
            real_cpu = data[0].to(device)
            batch_size_current = real_cpu.size(0)
            label = torch.full((batch_size_current,), real_label, dtype=torch.float, device=device)

            output = discriminator(real_cpu)
            errD_real = criterion(output, label)
            errD_real.backward()
            D_x = output.mean().item()

            # train with fake
            noise = torch.randn(batch_size_current, nz, 1, 1, device=device)
            fake = generator(noise)
            label.fill_(fake_label)
            output = discriminator(fake.detach())
            errD_fake = criterion(output, label)
            errD_fake.backward()
            D_G_z1 = output.mean().item()
            errD = errD_real + errD_fake
            optimizerD.step()

            ############################
            # (2) Update G network: maximize log(D(G(z)))
            ###########################
            generator.zero_grad()
            label.fill_(real_label)  # fake labels are real for generator cost
            output = discriminator(fake)
            errG = criterion(output, label)
            errG.backward()
            D_G_z2 = output.mean().item()
            optimizerG.step()

            # ========== ë¡œê¹… ==========
            if i % 50 == 0:
                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' 
                      % (epoch, niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))
            
            g_loss.append(errG.item())
            d_loss.append(errD.item())
            
            # ========== ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ==========
            if i % 100 == 0:
                print('[DCGAN] Saving sample images...')
                with torch.no_grad():
                    fake_sample = generator(fixed_noise).detach().cpu()
                img_list.append(utils.make_grid(fake_sample, padding=2, normalize=True))

    print(f"[DCGAN] Training completed! Final G_loss: {g_loss[-1]:.4f}, D_loss: {d_loss[-1]:.4f}")
    
    # í›ˆë ¨ ëª¨ë“œì—ì„œ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    generator.eval()
    discriminator.eval()
    
    return generator, discriminator


def train_gd_ungan_with_unseen(generator, discriminator, dataset, retain_idxs, forget_idxs, device,
                              lambda_adv=1.0, z_dim=100, batch_size=64, epochs=10, unseen_dataset=None, mixing_ratio=0.3):
    """
    ğŸ”„ ìˆ˜ì •ëœ ë¶„í¬ í˜¼í•©: Forget ë¶„í¬ íŠ¹ì„± + Unseen ì‹œê°ì  íŠ¹ì„±
    â†’ "Unseenì²˜ëŸ¼ ë³´ì´ë˜ Forget ë¶„í¬ë¥¼ ë”°ë¦„"
    """
    import torch
    import torch.nn as nn
    import torchvision.utils as utils
    
    # ========== í•˜ì´í¼íŒŒë¼ë¯¸í„° ==========
    niter = epochs
    batch_size = 128
    lr = 0.0002
    b1 = 0.5
    b2 = 0.999
    nz = z_dim
    
    # ========== ë¶„ë¦¬ëœ ë°ì´í„°ë¡œë” ì„¤ì • ==========
    forget_subset = torch.utils.data.Subset(dataset, forget_idxs)
    forget_loader = torch.utils.data.DataLoader(forget_subset, batch_size=batch_size//2, 
                                               shuffle=True, drop_last=True)
    
    if unseen_dataset is not None:
        #  í‰ê°€ìš©ê³¼ ë™ì¼í•˜ê²Œ ìˆ˜ëŸ‰ ë§ì¶¤ (forget_sizeì™€ ë™ì¼í•œ ìˆ˜ë¡œ ì œí•œ)
        forget_size = len(forget_idxs)
        if len(unseen_dataset) > forget_size:
            # ë¬´ì‘ìœ„ë¡œ forget_sizeë§Œí¼ ì„ íƒ
            unseen_indices = torch.randperm(len(unseen_dataset))[:forget_size]
            unseen_for_training = torch.utils.data.Subset(unseen_dataset, unseen_indices)
        else:
            unseen_for_training = unseen_dataset
            
        unseen_loader = torch.utils.data.DataLoader(unseen_for_training, batch_size=batch_size//2, 
                                                   shuffle=True, drop_last=True)
        print(f"[DCGAN] Using Forget: {len(forget_subset)} + Unseen: {len(unseen_for_training)} samples with REVERSED distribution mixing")
    else:
        print(f"[DCGAN] Using forget subset only: {len(forget_subset)} samples")
        
        return train_gd_ungan(generator, discriminator, dataset, retain_idxs, forget_idxs, device, lambda_adv, z_dim, batch_size, epochs)

    # ========== ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ==========
    criterion = nn.BCELoss()
    mse_criterion = nn.MSELoss()  # ë¶„í¬ í˜¼í•©ìš©
    optimizerD = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))
    optimizerG = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))
    
    # ========== ê³ ì • ë…¸ì´ì¦ˆ ë° ë¼ë²¨ ==========
    fixed_noise = torch.randn(64, nz, 1, 1, device=device)
    real_label = 1
    fake_label = 0
    
    # ========== í›ˆë ¨ ê¸°ë¡ìš© ==========
    img_list = []
    g_loss = []
    d_loss = []
    
    print(f"[DCGAN] Starting REVERSED distribution mixing training for {niter} epochs")
    print(f"[Target] Generate images that LOOK LIKE unseen but FOLLOW forget distribution")
    
    generator.train()
    discriminator.train()
    
    # ==========  ìˆ˜ì •ëœ ë¶„í¬ í˜¼í•© í›ˆë ¨ ë£¨í”„ ==========
    for epoch in range(niter):
        forget_iter = iter(forget_loader)
        unseen_iter = iter(unseen_loader)
        
        # ë” ì§§ì€ ë°ì´í„°ë¡œë”ì— ë§ì¶¤
        num_batches = min(len(forget_loader), len(unseen_loader))
        
        for i in range(num_batches):
            try:
                forget_batch = next(forget_iter)
                unseen_batch = next(unseen_iter)
            except StopIteration:
                break
                
            forget_imgs = forget_batch[0].to(device)
            unseen_imgs = unseen_batch[0].to(device)
            
            # ë°°ì¹˜ í¬ê¸° ë§ì¶¤
            min_batch = min(forget_imgs.size(0), unseen_imgs.size(0))
            forget_imgs = forget_imgs[:min_batch]
            unseen_imgs = unseen_imgs[:min_batch]
            
            ############################
            # (1) Update D network: í˜¼í•©ëœ real ë°ì´í„°ë¡œ í›ˆë ¨
            ###########################
            discriminator.zero_grad()
            
            # Real ë°ì´í„°: Forget + Unseen í˜¼í•©
            real_imgs = torch.cat([forget_imgs, unseen_imgs], dim=0)
            batch_size_current = real_imgs.size(0)
            
            label = torch.full((batch_size_current,), real_label, dtype=torch.float, device=device)
            output = discriminator(real_imgs)
            errD_real = criterion(output, label)
            errD_real.backward()
            D_x = output.mean().item()

            # Fake ë°ì´í„° ìƒì„± ë° íŒë³„
            noise = torch.randn(batch_size_current, nz, 1, 1, device=device)
            fake_imgs = generator(noise)
            label.fill_(fake_label)
            output = discriminator(fake_imgs.detach())
            errD_fake = criterion(output, label)
            errD_fake.backward()
            D_G_z1 = output.mean().item()
            errD = errD_real + errD_fake
            optimizerD.step()

            ############################
            # (2) ìˆ˜ì •ëœ Generator ì—…ë°ì´íŠ¸: REVERSED ë¶„í¬ í˜¼í•©
            ###########################
            generator.zero_grad()
            
            # Adversarial loss
            label.fill_(real_label)
            output = discriminator(fake_imgs)
            errG_adv = criterion(output, label)
            
            # í•µì‹¬ ìˆ˜ì •: ì—­ë°©í–¥ ë¶„í¬-ìŠ¤íƒ€ì¼ í˜¼í•©
            fake_forget_batch = fake_imgs[:min_batch]  # ì•ìª½ ì ˆë°˜ â†’ Forget ë¶„í¬ í•™ìŠµìš©
            fake_unseen_batch = fake_imgs[min_batch:]  # ë’¤ìª½ ì ˆë°˜ â†’ Unseen ìŠ¤íƒ€ì¼ í•™ìŠµìš©
            
            # **NEW**: Forgetì˜ ë¶„í¬ì  íŠ¹ì„± í•™ìŠµ (í†µê³„ì  êµ¬ì¡°)
            # ì±„ë„ë³„ í‰ê· ê³¼ ë¶„ì‚°ìœ¼ë¡œ ë¶„í¬ íŠ¹ì„± ìº¡ì²˜
            forget_dist_mean = forget_imgs.mean(dim=[0, 2, 3])  # [C] - ì±„ë„ë³„ ì „ì²´ í‰ê· 
            forget_dist_std = forget_imgs.std(dim=[0, 2, 3])    # [C] - ì±„ë„ë³„ ì „ì²´ ë¶„ì‚°
            
            fake_forget_dist_mean = fake_forget_batch.mean(dim=[0, 2, 3])
            fake_forget_dist_std = fake_forget_batch.std(dim=[0, 2, 3])
            
            # ë¶„í¬ ë§¤ì¹­ ì†ì‹¤ (Forgetì˜ í†µê³„ì  íŠ¹ì„±ì„ ë”°ë¼í•˜ê¸°)
            distribution_loss = (
                mse_criterion(fake_forget_dist_mean, forget_dist_mean) +
                mse_criterion(fake_forget_dist_std, forget_dist_std)
            ) / 2
            
            #  **NEW**: Unseenì˜ ì‹œê°ì  ìŠ¤íƒ€ì¼ í•™ìŠµ (ì™¸ê´€ì  íŠ¹ì§•)
            # í”½ì…€ ë ˆë²¨ íŒ¨í„´ê³¼ í…ìŠ¤ì²˜ íŠ¹ì„±ìœ¼ë¡œ ìŠ¤íƒ€ì¼ ìº¡ì²˜
            unseen_style_pattern = unseen_imgs.mean(dim=[2, 3])  # [B, C] - ì´ë¯¸ì§€ë³„ ì±„ë„ í‰ê· 
            fake_unseen_style_pattern = fake_unseen_batch.mean(dim=[2, 3])
            
            # ì¶”ê°€: ê³µê°„ì  ë³€í™”ëŸ‰ (í…ìŠ¤ì²˜ ë³µì¡ë„)
            unseen_spatial_var = torch.var(unseen_imgs.view(min_batch, -1), dim=1)  # [B] - ì´ë¯¸ì§€ë³„ í”½ì…€ ë¶„ì‚°
            fake_unseen_spatial_var = torch.var(fake_unseen_batch.view(min_batch, -1), dim=1)
            
            # ìŠ¤íƒ€ì¼ ë§¤ì¹­ ì†ì‹¤ (Unseenì˜ ì‹œê°ì  íŠ¹ì„±ì„ ë”°ë¼í•˜ê¸°)
            style_loss = (
                mse_criterion(fake_unseen_style_pattern, unseen_style_pattern) +
                mse_criterion(fake_unseen_spatial_var, unseen_spatial_var)
            ) / 2
            
            #  ìƒˆë¡œìš´ í˜¼í•© ë¹„ìœ¨: ë¶„í¬ 70% + ìŠ¤íƒ€ì¼ 30%
            # "Forget ë¶„í¬ë¥¼ ì–´ëŠ ì •ë„ ë”°ë¥´ê³ , Unseenì²˜ëŸ¼ ë³´ì´ê²Œ"
            distribution_weight = mixing_ratio  # 0.7 (ë¶„í¬ê°€ ë” ì¤‘ìš”)
            style_weight = 1 - mixing_ratio              # 0.3 (ìŠ¤íƒ€ì¼ì€ ë³´ì¡°)
            
            errG_mixing = distribution_weight * distribution_loss + style_weight * style_loss
            
            # ì „ì²´ Generator ì†ì‹¤
            errG = errG_adv + lambda_adv * errG_mixing
            errG.backward()
            D_G_z2 = output.mean().item()
            optimizerG.step()

            # ========== ë¡œê¹… ==========
            if i % 25 == 0:  # ë” ìì£¼ ë¡œê¹…
                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f (Adv: %.4f, Dist: %.4f, Style: %.4f) D(x): %.4f D(G(z)): %.4f / %.4f' 
                      % (epoch, niter, i, num_batches, errD.item(), errG.item(), errG_adv.item(), 
                         distribution_loss.item(), style_loss.item(), D_x, D_G_z1, D_G_z2))
            
            g_loss.append(errG.item())
            d_loss.append(errD.item())
            
            # ========== ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ==========
            if i % 50 == 0:
                print('[DCGAN] Saving REVERSED distribution-mixed sample images...')
                with torch.no_grad():
                    fake_sample = generator(fixed_noise).detach().cpu()
                img_list.append(utils.make_grid(fake_sample, padding=2, normalize=True))

    print(f"[DCGAN] REVERSED Distribution mixing training completed! Final G_loss: {g_loss[-1]:.4f}, D_loss: {d_loss[-1]:.4f}")
    print(f"[Result] Generated images should LOOK LIKE unseen but FOLLOW forget distribution patterns")
    
    generator.eval()
    discriminator.eval()
    
    return generator, discriminator



def train_gd_ungan_unseen_only(generator, discriminator, dataset, retain_idxs, forget_idxs, device,
                              lambda_adv=1.0, z_dim=100, batch_size=64, epochs=10, unseen_dataset=None):
    """
    Unseen ë°ì´í„°ë§Œ ì‚¬ìš©í•œ DCGAN í›ˆë ¨: ìˆœìˆ˜ Unseen ë¶„í¬ í•™ìŠµ
    â†’ "Unseen ë°ì´í„°ì˜ íŠ¹ì„±ë§Œìœ¼ë¡œ í•©ì„± ë°ì´í„° ìƒì„±"
    """
    import torch
    import torch.nn as nn
    import torchvision.utils as utils
    
    # ========== í•˜ì´í¼íŒŒë¼ë¯¸í„° ==========
    niter = epochs
    batch_size = 128
    lr = 0.0002
    b1 = 0.5
    b2 = 0.999
    nz = z_dim
    
    # ========== Unseen ë°ì´í„°ë¡œë” ì„¤ì • ==========
    if unseen_dataset is not None:
        # forget_sizeì™€ ë™ì¼í•œ ìˆ˜ëŸ‰ìœ¼ë¡œ ì œí•œ
        forget_size = len(forget_idxs)
        if len(unseen_dataset) > forget_size:
            # ë¬´ì‘ìœ„ë¡œ forget_sizeë§Œí¼ ì„ íƒ
            unseen_indices = torch.randperm(len(unseen_dataset))[:forget_size]
            unseen_for_training = torch.utils.data.Subset(unseen_dataset, unseen_indices)
        else:
            unseen_for_training = unseen_dataset
            
        unseen_loader = torch.utils.data.DataLoader(unseen_for_training, batch_size=batch_size, 
                                                   shuffle=True, drop_last=True)
        print(f"[DCGAN] Using UNSEEN ONLY: {len(unseen_for_training)} samples for pure unseen distribution learning")
    else:
        print(f"[DCGAN] No unseen dataset provided, falling back to retain data")
        return train_gd_ungan(generator, discriminator, dataset, retain_idxs, forget_idxs, device, lambda_adv, z_dim, batch_size, epochs)

    # ========== ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ==========
    criterion = nn.BCELoss()
    optimizerD = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))
    optimizerG = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))
    
    # ========== ê³ ì • ë…¸ì´ì¦ˆ ë° ë¼ë²¨ ==========
    fixed_noise = torch.randn(64, nz, 1, 1, device=device)
    real_label = 1
    fake_label = 0
    
    # ========== í›ˆë ¨ ê¸°ë¡ìš© ==========
    img_list = []
    g_loss = []
    d_loss = []
    
    print(f"[DCGAN] Starting UNSEEN ONLY training for {niter} epochs")
    print(f"[Target] Generate images following pure unseen data distribution")
    
    generator.train()
    discriminator.train()
    
    # ========== ìˆœìˆ˜ Unseen ë°ì´í„° í›ˆë ¨ ë£¨í”„ ==========
    for epoch in range(niter):
        for i, data in enumerate(unseen_loader, 0):
            unseen_imgs = data[0].to(device)
            batch_size_current = unseen_imgs.size(0)
            
            ############################
            # (1) Update D network: Unseen ë°ì´í„°ë¡œë§Œ í›ˆë ¨
            ###########################
            discriminator.zero_grad()
            
            # Real ë°ì´í„°: Unseenë§Œ ì‚¬ìš©
            label = torch.full((batch_size_current,), real_label, dtype=torch.float, device=device)
            output = discriminator(unseen_imgs)
            errD_real = criterion(output, label)
            errD_real.backward()
            D_x = output.mean().item()

            # Fake ë°ì´í„° ìƒì„± ë° íŒë³„
            noise = torch.randn(batch_size_current, nz, 1, 1, device=device)
            fake_imgs = generator(noise)
            label.fill_(fake_label)
            output = discriminator(fake_imgs.detach())
            errD_fake = criterion(output, label)
            errD_fake.backward()
            D_G_z1 = output.mean().item()
            errD = errD_real + errD_fake
            optimizerD.step()

            ############################
            # (2) Update G network: ìˆœìˆ˜ Adversarial í•™ìŠµ
            ###########################
            generator.zero_grad()
            
            # GeneratorëŠ” Discriminatorë¥¼ ì†ì—¬ì•¼ í•˜ë¯€ë¡œ ì§„ì§œ(1) ë ˆì´ë¸”ë¡œ í•™ìŠµ
            label.fill_(real_label)
            output = discriminator(fake_imgs)
            errG = criterion(output, label)
            errG.backward()
            D_G_z2 = output.mean().item()
            optimizerG.step()

            # ========== ë¡œê¹… ==========
            if i % 50 == 0:
                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' 
                      % (epoch, niter, i, len(unseen_loader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))
            
            g_loss.append(errG.item())
            d_loss.append(errD.item())
            
            # ========== ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ==========
            if i % 100 == 0:
                print('[DCGAN] Saving UNSEEN ONLY sample images...')
                with torch.no_grad():
                    fake_sample = generator(fixed_noise).detach().cpu()
                img_list.append(utils.make_grid(fake_sample, padding=2, normalize=True))

    print(f"[DCGAN] UNSEEN ONLY training completed! Final G_loss: {g_loss[-1]:.4f}, D_loss: {d_loss[-1]:.4f}")
    print(f"[Result] Generated images follow pure unseen data distribution")
    
    generator.eval()
    discriminator.eval()
    
    return generator, discriminator


def train_gd_ungan_forget_only(generator, discriminator, dataset, retain_idxs, forget_idxs, device,
                              lambda_adv=1.0, z_dim=100, batch_size=64, epochs=10, unseen_dataset=None):
    """
    Forget ë°ì´í„°ë§Œ ì‚¬ìš©í•œ DCGAN í›ˆë ¨: ìˆœìˆ˜ Forget ë¶„í¬ í•™ìŠµ
    â†’ "Forget ë°ì´í„°ì˜ íŠ¹ì„±ë§Œìœ¼ë¡œ í•©ì„± ë°ì´í„° ìƒì„±"
    """
    import torch
    import torch.nn as nn
    import torchvision.utils as utils
    
    # ========== í•˜ì´í¼íŒŒë¼ë¯¸í„° ==========
    niter = epochs
    batch_size = 128
    lr = 0.0002
    b1 = 0.5
    b2 = 0.999
    nz = z_dim
    
    # ========== Forget ë°ì´í„°ë¡œë” ì„¤ì • ==========
    forget_subset = torch.utils.data.Subset(dataset, forget_idxs)
    forget_loader = torch.utils.data.DataLoader(forget_subset, batch_size=batch_size, 
                                               shuffle=True, drop_last=True)
    print(f"[DCGAN] Using FORGET ONLY: {len(forget_subset)} samples for pure forget distribution learning")

    # ========== ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ==========
    criterion = nn.BCELoss()
    optimizerD = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))
    optimizerG = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))
    
    # ========== ê³ ì • ë…¸ì´ì¦ˆ ë° ë¼ë²¨ ==========
    fixed_noise = torch.randn(64, nz, 1, 1, device=device)
    real_label = 1
    fake_label = 0
    
    # ========== í›ˆë ¨ ê¸°ë¡ìš© ==========
    img_list = []
    g_loss = []
    d_loss = []
    
    print(f"[DCGAN] Starting FORGET ONLY training for {niter} epochs")
    print(f"[Target] Generate images following pure forget data distribution")
    
    generator.train()
    discriminator.train()
    
    # ========== ìˆœìˆ˜ Forget ë°ì´í„° í›ˆë ¨ ë£¨í”„ ==========
    for epoch in range(niter):
        for i, data in enumerate(forget_loader, 0):
            forget_imgs = data[0].to(device)
            batch_size_current = forget_imgs.size(0)
            
            ############################
            # (1) Update D network: Forget ë°ì´í„°ë¡œë§Œ í›ˆë ¨
            ###########################
            discriminator.zero_grad()
            
            # Real ë°ì´í„°: Forgetë§Œ ì‚¬ìš©
            label = torch.full((batch_size_current,), real_label, dtype=torch.float, device=device)
            output = discriminator(forget_imgs)
            errD_real = criterion(output, label)
            errD_real.backward()
            D_x = output.mean().item()

            # Fake ë°ì´í„° ìƒì„± ë° íŒë³„
            noise = torch.randn(batch_size_current, nz, 1, 1, device=device)
            fake_imgs = generator(noise)
            label.fill_(fake_label)
            output = discriminator(fake_imgs.detach())
            errD_fake = criterion(output, label)
            errD_fake.backward()
            D_G_z1 = output.mean().item()
            errD = errD_real + errD_fake
            optimizerD.step()

            ############################
            # (2) Update G network: ìˆœìˆ˜ Adversarial í•™ìŠµ
            ###########################
            generator.zero_grad()
            
            # GeneratorëŠ” Discriminatorë¥¼ ì†ì—¬ì•¼ í•˜ë¯€ë¡œ ì§„ì§œ(1) ë ˆì´ë¸”ë¡œ í•™ìŠµ
            label.fill_(real_label)
            output = discriminator(fake_imgs)
            errG = criterion(output, label)
            errG.backward()
            D_G_z2 = output.mean().item()
            optimizerG.step()

            # ========== ë¡œê¹… ==========
            if i % 50 == 0:
                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' 
                      % (epoch, niter, i, len(forget_loader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))
            
            g_loss.append(errG.item())
            d_loss.append(errD.item())
            
            # ========== ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ==========
            if i % 100 == 0:
                print('[DCGAN] Saving FORGET ONLY sample images...')
                with torch.no_grad():
                    fake_sample = generator(fixed_noise).detach().cpu()
                img_list.append(utils.make_grid(fake_sample, padding=2, normalize=True))

    print(f"[DCGAN] FORGET ONLY training completed! Final G_loss: {g_loss[-1]:.4f}, D_loss: {d_loss[-1]:.4f}")
    print(f"[Result] Generated images follow pure forget data distribution")
    
    generator.eval()
    discriminator.eval()
    
    return generator, discriminator


# -------------------- Synthetic Dataset ì •ì˜ --------------------
class SyntheticImageDataset(torch.utils.data.Dataset):
    """í•©ì„± ì´ë¯¸ì§€ ë°ì´í„°ì…‹ (ìˆ˜ì •ëœ ë²„ì „)"""
    
    def __init__(self, images, labels):
        self.images = images
        #  ë¼ë²¨ì„ í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥
        if isinstance(labels, torch.Tensor):
            self.labels = labels
        else:
            self.labels = torch.tensor(labels, dtype=torch.long)
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]
        
        #  ë‘˜ ë‹¤ í…ì„œë¡œ ë°˜í™˜í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥
        if not isinstance(image, torch.Tensor):
            image = torch.tensor(image)
        if not isinstance(label, torch.Tensor):
            label = torch.tensor(label, dtype=torch.long)
            
        return image, label


# -------------------- IID ë¶„ë°° --------------------
def partition_synthetic_data_iid(dataset, num_users):
    num_items = int(len(dataset) / num_users)
    indices = np.random.permutation(len(dataset))
    user_groups = {}

    for i in range(num_users):
        user_groups[i] = indices[i * num_items:(i + 1) * num_items].tolist()

    return user_groups


# -------------------- Non-IID ë¶„ë°° --------------------
def partition_synthetic_data_dirichlet(dataset, num_users, alpha=0.5, num_classes=10):
    """
    Synthetic ë°ì´í„°ì…‹ì„ Dirichlet ë¶„í¬ ê¸°ë°˜ìœ¼ë¡œ Non-IIDí•˜ê²Œ ë¶„í• 

    Args:
        dataset: SyntheticImageDataset 
        num_users: ì‚¬ìš©ì ìˆ˜ (ì–¸ëŸ¬ë‹ í´ë¼ì´ì–¸íŠ¸ ì œì™¸, ì¦‰ 9ëª…)
        alpha: Dirichlet ë¶„í¬ì˜ ì§‘ì¤‘ë„ (ì‘ì„ìˆ˜ë¡ í¸í–¥ í¼)
        num_classes: ì´ í´ë˜ìŠ¤ ìˆ˜

    Returns:
        user_groups: Dict[user_id] = list of sample indices
    """
    if isinstance(dataset.labels, torch.Tensor):
        labels = dataset.labels.cpu().numpy()
    else:
        labels = np.array(dataset.labels)

    user_groups = {i: [] for i in range(num_users)}
    idxs = np.arange(len(dataset))

    # í´ë˜ìŠ¤ë³„ ì¸ë±ìŠ¤ ê·¸ë£¹í™”
    class_indices = [idxs[labels == y] for y in range(num_classes)]

    for c in range(num_classes):
        np.random.shuffle(class_indices[c])
        class_size = len(class_indices[c])

        proportions = np.random.dirichlet(np.repeat(alpha, num_users))
        proportions = np.array([
            p * (len(user_groups[i]) < len(dataset) / num_users)
            for i, p in enumerate(proportions)
        ])
        proportions = proportions / proportions.sum()
        proportions = (np.cumsum(proportions) * class_size).astype(int)[:-1]

        split = np.split(class_indices[c], proportions)
        for i, idx in enumerate(split):
            user_groups[i] += idx.tolist()

    return user_groups




# -------------------- Subset ì¶”ì¶œ --------------------
def get_synthetic_subset(dataset, user_groups, user_idx):
    return Subset(dataset, user_groups[user_idx])
