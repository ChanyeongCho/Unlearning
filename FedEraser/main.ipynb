{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47e5ba1",
   "metadata": {},
   "source": [
    "# 연합학습 환경에서의 머신 언러닝 기법\n",
    "\n",
    "1. 언러닝의 목표가 무엇인가? \n",
    ": 서버를 속이는 것인가? 클라이언트를 속이는 것인가? 아니면 외부 공격자를 속이는 것인가\n",
    "\n",
    "2. 데이터를 생성하는 건 좋은데 이걸 언러닝 목표에 맞게 어떻게 활용할 것인가?\n",
    ": retrain 했을 때와 비슷한 성능을 지니면서, 시간적으로 효율적이고, 다른 언러닝 기법과 비교했을 때 성능이 보장되어야함\n",
    "\n",
    "3. 항상 default 값으로 같이 비교할 수치\n",
    ": original 모델(언러닝을 진행하지 않은 연합학습 모델), retrain 모델(언러닝 요청이 들어와 언러닝 클라이언트를 제외하고 나머지 클라이언트만 다시 학습), fine-tune 모델 (데이터 생성을 통한 언러닝 적용)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b47a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt     \n",
    "import torchvision.utils as vutils \n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Subset #unseen data를 통해서 언러닝 재학습에서 사용.\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from evaluate_mia import evaluate_model_comparison\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference\n",
    "from models import CNNMnist,ResNet18, CNNCifar, Generator, Discriminator, generate_images, filter_images\n",
    "from utils import get_dataset, average_weights, exp_details, create_poisoned_dataset, generate_fixed_threshold_data\n",
    "from unlearn import (\n",
    "    train_generator_ungan,\n",
    "    train_gd_ungan,\n",
    "    train_gd_ungan_with_unseen,\n",
    "    train_gd_ungan_unseen_only, \n",
    "    train_gd_ungan_forget_only,\n",
    "    SyntheticImageDataset, \n",
    "    partition_synthetic_data_iid,\n",
    "    partition_synthetic_data_dirichlet,\n",
    "    get_synthetic_subset\n",
    ")\n",
    "from evaluate_mia import evaluate_mia, comprehensive_evaluation, evaluate_synthetic_classification_accuracy, evaluate_classification_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_real_vs_generated_with_filtering(generator, discriminator, dataset, forget_idxs, \n",
    "                                             z_dim=100, device='cpu', threshold=0.5, num_samples=16):\n",
    "    \"\"\"\n",
    "    실제 이미지, 생성된 이미지, 필터링된 이미지를 모두 비교 시각화\n",
    "    \"\"\"\n",
    "    # 실제 이미지 샘플링\n",
    "    real_images = []\n",
    "    sample_idxs = np.random.choice(forget_idxs, min(num_samples, len(forget_idxs)), replace=False)\n",
    "    \n",
    "    for idx in sample_idxs:\n",
    "        img, _ = dataset[idx]\n",
    "        real_images.append(img)\n",
    "    \n",
    "    real_images = torch.stack(real_images)\n",
    "    \n",
    "    # 더 많은 이미지를 생성해서 필터링 효과를 보여주기\n",
    "    num_generate = num_samples * 2  # 2배 생성해서 필터링\n",
    "    \n",
    "    # 생성된 이미지\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    with torch.no_grad():\n",
    "        # 기존: noise = torch.randn(num_generate, z_dim, device=device)\n",
    "        # 수정: DCGAN 형식으로 (batch, z_dim, 1, 1)\n",
    "        noise = torch.randn(num_generate, z_dim, 1, 1, device=device)\n",
    "        \n",
    "        generated_images = generator(noise)\n",
    "        \n",
    "        # Discriminator로 품질 평가\n",
    "        d_scores = discriminator(generated_images.to(device))\n",
    "        \n",
    "        # CPU로 이동하고 정규화\n",
    "        generated_images = generated_images.cpu()\n",
    "        generated_images = torch.clamp(generated_images, -1, 1)\n",
    "        generated_images = (generated_images + 1) / 2\n",
    "        \n",
    "        # 필터링 (threshold 이상만 선택)\n",
    "        d_scores = d_scores.cpu().squeeze()\n",
    "        high_quality_mask = d_scores > threshold\n",
    "        \n",
    "        if high_quality_mask.sum() > 0:\n",
    "            filtered_images = generated_images[high_quality_mask]\n",
    "            filtered_scores = d_scores[high_quality_mask]\n",
    "            # 상위 num_samples개만 선택\n",
    "            if len(filtered_images) > num_samples:\n",
    "                top_indices = torch.topk(filtered_scores, num_samples)[1]\n",
    "                filtered_images = filtered_images[top_indices]\n",
    "        else:\n",
    "            # 필터링된 이미지가 없으면 상위 점수 이미지들 선택\n",
    "            top_indices = torch.topk(d_scores, num_samples)[1]\n",
    "            filtered_images = generated_images[top_indices]\n",
    "    \n",
    "    # 실제 이미지 정규화\n",
    "    if real_images.min() < 0:  # 이미 정규화된 경우\n",
    "        real_images = (real_images + 1) / 2\n",
    "    elif real_images.max() > 1:  # 0-255 범위\n",
    "        real_images = real_images / 255.0\n",
    "    \n",
    "    # 3행으로 비교 시각화\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 9))\n",
    "    \n",
    "    # 실제 이미지\n",
    "    real_grid = vutils.make_grid(real_images, nrow=8, normalize=False, padding=2)\n",
    "    real_grid_np = real_grid.permute(1, 2, 0).numpy()\n",
    "    ax1.imshow(real_grid_np, cmap='gray' if real_images.shape[1] == 1 else None)\n",
    "    ax1.set_title('Real Images (Forget Set)', fontsize=14)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # 모든 생성된 이미지 (처음 num_samples개)\n",
    "    all_gen_grid = vutils.make_grid(generated_images[:num_samples], nrow=8, normalize=False, padding=2)\n",
    "    all_gen_grid_np = all_gen_grid.permute(1, 2, 0).numpy()\n",
    "    ax2.imshow(all_gen_grid_np, cmap='gray' if generated_images.shape[1] == 1 else None)\n",
    "    ax2.set_title('All Generated Images', fontsize=14)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # 필터링된 고품질 이미지\n",
    "    filtered_grid = vutils.make_grid(filtered_images, nrow=8, normalize=False, padding=2)\n",
    "    filtered_grid_np = filtered_grid.permute(1, 2, 0).numpy()\n",
    "    ax3.imshow(filtered_grid_np, cmap='gray' if filtered_images.shape[1] == 1 else None)\n",
    "    ax3.set_title(f'High-Quality Filtered Images (D-score > {threshold})', fontsize=14)\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./real_vs_generated_filtered.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Discriminator 점수 통계 출력\n",
    "    print(f\"Discriminator Scores - Mean: {d_scores.mean():.3f}, Std: {d_scores.std():.3f}\")\n",
    "    print(\"Comparison image saved to: ./real_vs_generated_filtered.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ef2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_dataset_to_device(dataset, device):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for x, y in dataset:\n",
    "        images.append(x.to(device))\n",
    "        labels.append(torch.tensor(y).to(device))\n",
    "    return TensorDataset(torch.stack(images), torch.stack(labels))\n",
    "\n",
    "\n",
    "def add_backdoor_trigger(x):\n",
    "    x_bd = x.clone()\n",
    "    x_bd[:, 25:28, 25:28] = 0.9\n",
    "    return x_bd\n",
    "\n",
    "def evaluate_backdoor_asr(model, dataset, target_label, device):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            x, y = dataset[i]\n",
    "            # 백도어 트리거 삽입\n",
    "            x_bd = add_backdoor_trigger(x).to(device)\n",
    "            x_bd = x_bd.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "            output = model(x_bd)\n",
    "            pred = output.argmax(dim=1).item()\n",
    "\n",
    "            total += 1\n",
    "            if pred == target_label:\n",
    "                correct += 1\n",
    "\n",
    "    asr = correct / total\n",
    "    return asr\n",
    "\n",
    "def select_model(args, train_dataset):\n",
    "    if args.model == 'cnn':\n",
    "        if args.dataset == 'cifar':\n",
    "            return CNNCifar(args=args)  # CIFAR-10용 CNN 추가 필요\n",
    "        else:\n",
    "            return CNNMnist(args=args)  # MNIST용 CNN\n",
    "    elif args.model == 'resnet':\n",
    "        return ResNet18(num_classes=args.num_classes)  # CIFAR-10용 ResNet\n",
    "    else:\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    args = args_parser()\n",
    "    \n",
    "    # ===================== 0. 랜덤 시드 설정 (재현성) =====================\n",
    "    seed = 42\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "    \n",
    "    device = 'cuda' if args.gpu and torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    exp_details(args)\n",
    "\n",
    "    # ===================== 1. 데이터셋 로딩 및 초기화 =====================\n",
    "    train_dataset, test_dataset, unseen_dataset, user_groups = get_dataset(args)\n",
    "    full_dataset = train_dataset  \n",
    "\n",
    "    global_model = select_model(args, full_dataset).to(device)\n",
    "    global_model.train()\n",
    "\n",
    "    if args.dataset == 'cifar':\n",
    "        generator = Generator(z_dim=args.z_dim, img_shape=(3, 32, 32)).to(device)      \n",
    "        discriminator = Discriminator(img_shape=(3, 32, 32)).to(device)                \n",
    "    else:\n",
    "        generator = Generator(z_dim=args.z_dim).to(device)\n",
    "        discriminator = Discriminator().to(device)\n",
    "\n",
    "    # DCGAN 가중치 초기화 적용\n",
    "    from models import weights_init\n",
    "\n",
    "    generator.apply(weights_init)\n",
    "    discriminator.apply(weights_init)\n",
    "    \n",
    "    global_weights = global_model.state_dict()\n",
    "    train_loss, train_accuracy = [], []\n",
    "\n",
    "    forget_client = 0\n",
    "    forget_idxs = user_groups[forget_client]\n",
    "    retain_idxs = [i for i in range(len(train_dataset)) if i not in forget_idxs]\n",
    "    test_idxs = np.random.choice(len(test_dataset), len(forget_idxs), replace=False)\n",
    "\n",
    "    # Source-Free를 위한 IID Unseen 데이터 준비\n",
    "    from utils import create_iid_unseen_data\n",
    "    \n",
    "    iid_unseen_dataset = create_iid_unseen_data(unseen_dataset, forget_idxs, train_dataset)\n",
    "    \n",
    "    # 데이터 분배 정보 출력 \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"DATASET DISTRIBUTION\".center(70))\n",
    "    print(\"-\"*70)\n",
    "    print(f\"Total Training Data: {len(full_dataset):,}\")\n",
    "    print(f\"Test Data: {len(test_dataset):,}\")\n",
    "    print(f\"Unseen Data Pool: {len(unseen_dataset):,}\")\n",
    "    print(f\"\\nFederated Learning Setup:\")\n",
    "    print(f\"   Forget Set Size: {len(forget_idxs):,}\")\n",
    "    print(f\"   Retain Set Size: {len(retain_idxs):,}\")\n",
    "    print(f\"   IID Unseen Data for Generation: {len(iid_unseen_dataset):,}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    # ===================== 2. Original 연합학습 (FedAvg 방식) =====================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"PHASE 1: Original FEDERATED LEARNING\".center(70))\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    fedavg_start_time = time.time()\n",
    "    unlearning_request_epoch = args.epochs // 2\n",
    "    unlearning_requested = False\n",
    "\n",
    "    for epoch in tqdm(range(args.epochs), desc='Original FL Training'):\n",
    "        if epoch == unlearning_request_epoch and not unlearning_requested:\n",
    "            print(f\"\\n[UNLEARNING REQUEST] Client {forget_client} requests unlearning at epoch {epoch + 1}\")\n",
    "            unlearning_requested = True\n",
    "            # 언러닝 요청 시점의 모델 저장\n",
    "            unlearning_request_model = copy.deepcopy(global_model)\n",
    "            break  # 언러닝 요청시 기존 FL 중단\n",
    "\n",
    "        local_weights, local_losses = [], []\n",
    "        m = max(int(args.frac * args.num_users), 1)\n",
    "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "\n",
    "        for idx in idxs_users:\n",
    "            local_model = LocalUpdate(args=args, dataset=full_dataset, idxs=user_groups[idx])\n",
    "            w, loss = local_model.update_weights(model=copy.deepcopy(global_model), global_round=epoch)\n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(loss)\n",
    "\n",
    "        global_weights = average_weights(local_weights)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "        \n",
    "        loss_avg = sum(local_losses) / len(local_losses)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            acc, _ = test_inference(args, global_model, test_dataset)\n",
    "            print(f\"[Standard FL] Epoch {epoch+1}/{args.epochs} | Loss: {loss_avg:.4f} | Acc: {acc*100:.2f}%\")\n",
    "\n",
    "    fedavg_time = time.time() - fedavg_start_time\n",
    "    \n",
    "    # 언러닝 요청이 없었다면 전체 학습 완료 모델 사용\n",
    "    if not unlearning_requested:\n",
    "        unlearning_request_model = copy.deepcopy(global_model)\n",
    "\n",
    "    # ===================== 3. Source-Free 합성 데이터 생성 =====================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"PHASE 2: SOURCE-FREE SYNTHETIC DATA GENERATION\".center(70))\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    generation_start_time = time.time()\n",
    "    \n",
    "    print(\"[Source-Free] Server provides IID unseen data to unlearning client...\")\n",
    "    print(\"[Source-Free] Client generates synthetic data without direct forget data access...\")\n",
    "    \n",
    "    # FedEraser와 결합한 Source-Free 생성: Forget 분포 + Unseen 스타일\n",
    "    generator, discriminator = train_gd_ungan_with_unseen(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        dataset=full_dataset,\n",
    "        retain_idxs=retain_idxs,\n",
    "        forget_idxs=forget_idxs,\n",
    "        device=device,\n",
    "        lambda_adv=1.0,\n",
    "        z_dim=args.z_dim,\n",
    "        batch_size=64,\n",
    "        epochs=200,  \n",
    "        unseen_dataset=iid_unseen_dataset,\n",
    "        mixing_ratio=0.5  \n",
    "    )\n",
    "\n",
    "    # 합성 데이터 생성\n",
    "    synthetic_images, synthetic_labels = generate_fixed_threshold_data(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        forget_idxs=forget_idxs,\n",
    "        dataset=full_dataset,\n",
    "        device=device,\n",
    "        z_dim=args.z_dim,\n",
    "        target_count=len(forget_idxs),\n",
    "        fixed_threshold=args.gen_threshold,\n",
    "        batch_size=64\n",
    "    )\n",
    "\n",
    "    synthetic_dataset = SyntheticImageDataset(synthetic_images, synthetic_labels)\n",
    "    generation_time = time.time() - generation_start_time\n",
    "    \n",
    "    print(f\"[Source-Free] Generated {len(synthetic_images):,} synthetic samples in {generation_time:.2f}s\")\n",
    "\n",
    "    # ===================== 4. 단순화된 FedEraser 언러닝 =====================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"PHASE 3: SIMPLIFIED FEDERASER UNLEARNING PROCESS\".center(70))\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    unlearning_start_time = time.time()\n",
    "    \n",
    "    # 4-1. 언러닝 직전 상태에서 언러닝 클라이언트 제외한 가중치 저장\n",
    "    print(\"[FedEraser] Saving pre-unlearning weights excluding unlearning client...\")\n",
    "    \n",
    "    # 언러닝 클라이언트 제외한 나머지 클라이언트들의 평균 가중치 계산\n",
    "    other_clients = list(range(args.num_users))\n",
    "    other_clients.remove(forget_client)\n",
    "    \n",
    "    # 언러닝 요청 직전 상태에서 나머지 클라이언트들만의 가중치 근사 계산\n",
    "    # 실제로는 언러닝 요청 시점의 글로벌 모델에서 언러닝 클라이언트 기여도를 제외\n",
    "    exclude_unlearn_weights = copy.deepcopy(unlearning_request_model.state_dict())\n",
    "    \n",
    "    # 4-2. 언러닝 클라이언트: 합성 데이터로 로컬 학습\n",
    "    print(\"[FedEraser] Unlearning client training with synthetic data...\")\n",
    "    unlearn_local = LocalUpdate(args=args, dataset=synthetic_dataset)\n",
    "    unlearn_weights, unlearn_loss, unlearn_delta = unlearn_local.synthetic_update_weights(\n",
    "        model=copy.deepcopy(unlearning_request_model), \n",
    "        global_round=0,\n",
    "        synthetic_dataset=synthetic_dataset\n",
    "    )\n",
    "    \n",
    "    print(f\"[FedEraser] Unlearning client completed local training with loss: {unlearn_loss:.4f}\")\n",
    "    \n",
    "    # 4-3. 가중치 조합 (단순화된 FedEraser)\n",
    "    print(\"[FedEraser] Combining weights...\")\n",
    "    \n",
    "    # 단순한 가중 평균: 기존 (언러닝 클라이언트 제외) + 새로운 언러닝 가중치\n",
    "    num_other_clients = len(other_clients)\n",
    "    total_clients = num_other_clients + 1  # 언러닝 클라이언트 포함\n",
    "    \n",
    "    combined_weights = {}\n",
    "    for key in exclude_unlearn_weights.keys():\n",
    "        # 가중 평균: (나머지 클라이언트 가중치 * 수) + (언러닝 클라이언트 가중치 * 1) / 전체\n",
    "        combined_weights[key] = (\n",
    "            exclude_unlearn_weights[key] * num_other_clients + \n",
    "            unlearn_weights[key] * 1\n",
    "        ) / total_clients\n",
    "    \n",
    "    # 4-4. 언러닝된 모델 생성\n",
    "    finetune_model = copy.deepcopy(unlearning_request_model)\n",
    "    finetune_model.load_state_dict(combined_weights)\n",
    "    \n",
    "    print(\"[FedEraser] Weight combination completed\")\n",
    "    \n",
    "    # 4-5. 언러닝 클라이언트 제외하고 연합학습 재개\n",
    "    print(\"[FedEraser] Resuming federated learning without unlearning client...\")\n",
    "    \n",
    "    remaining_epochs = args.epochs - unlearning_request_epoch - 1\n",
    "    for epoch in tqdm(range(remaining_epochs), desc='Post-Unlearning FL'):\n",
    "        local_weights, local_losses = [], []\n",
    "        \n",
    "        # 언러닝 클라이언트 제외한 연합학습\n",
    "        m = max(int(args.frac * len(other_clients)), 1)\n",
    "        idxs_users = np.random.choice(other_clients, m, replace=False)\n",
    "\n",
    "        for idx in idxs_users:\n",
    "            local_model = LocalUpdate(args=args, dataset=full_dataset, idxs=user_groups[idx])\n",
    "            w, loss = local_model.update_weights(model=copy.deepcopy(finetune_model), global_round=epoch)\n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(loss)\n",
    "\n",
    "        if local_weights:\n",
    "            global_weights = average_weights(local_weights)\n",
    "            finetune_model.load_state_dict(global_weights)\n",
    "            \n",
    "            loss_avg = sum(local_losses) / len(local_losses)\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(f\"[Post-Unlearning FL] Epoch {epoch+1}/{remaining_epochs} | Loss: {loss_avg:.4f}\")\n",
    "\n",
    "    unlearning_time = time.time() - unlearning_start_time\n",
    "\n",
    "    # ===================== 5. Original 모델 (언러닝 요청 무시) =====================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"BASELINE: ORIGINAL MODEL (IGNORING UNLEARNING)\".center(70))\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    original_continue_start = time.time()\n",
    "    original_model = copy.deepcopy(unlearning_request_model)\n",
    "    \n",
    "    # 언러닝 요청을 무시하고 모든 클라이언트와 계속 학습\n",
    "    remaining_epochs = args.epochs - unlearning_request_epoch - 1\n",
    "    for epoch in tqdm(range(remaining_epochs), desc='Original Continue Training'):\n",
    "        local_weights, local_losses = [], []\n",
    "        m = max(int(args.frac * args.num_users), 1)\n",
    "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "\n",
    "        for idx in idxs_users:\n",
    "            local_model = LocalUpdate(args=args, dataset=full_dataset, idxs=user_groups[idx])\n",
    "            w, loss = local_model.update_weights(model=copy.deepcopy(original_model), global_round=epoch)\n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(loss)\n",
    "\n",
    "        global_weights = average_weights(local_weights)\n",
    "        original_model.load_state_dict(global_weights)\n",
    "\n",
    "    original_continue_time = time.time() - original_continue_start\n",
    "\n",
    "    # ===================== 6. Retrain 모델 (이상적인 기준점) =====================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"BASELINE: RETRAIN MODEL (IDEAL UNLEARNING)\".center(70))\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    retrain_start_time = time.time()\n",
    "    retrain_model = select_model(args, full_dataset).to(device)\n",
    "    \n",
    "    # 언러닝 클라이언트 제외하고 처음부터 재훈련\n",
    "    for epoch in tqdm(range(args.epochs), desc='Retrain FL Training'):\n",
    "        local_weights, local_losses = [], []\n",
    "        m = max(int(args.frac * len(other_clients)), 1)\n",
    "        idxs_users = np.random.choice(other_clients, m, replace=False)\n",
    "\n",
    "        for idx in idxs_users:\n",
    "            local_model = LocalUpdate(args=args, dataset=full_dataset, idxs=user_groups[idx])\n",
    "            w, loss = local_model.update_weights(model=copy.deepcopy(retrain_model), global_round=epoch)\n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(loss)\n",
    "\n",
    "        if local_weights:\n",
    "            global_weights = average_weights(local_weights)\n",
    "            retrain_model.load_state_dict(global_weights)\n",
    "\n",
    "    retrain_time = time.time() - retrain_start_time\n",
    "\n",
    "    # ===================== 7. 종합 평가 =====================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"COMPREHENSIVE EVALUATION\".center(70))\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    \n",
    "    evaluation_results = evaluate_model_comparison(\n",
    "        original_model=original_model,\n",
    "        retrain_model=retrain_model,\n",
    "        finetune_model=finetune_model,\n",
    "        train_dataset=full_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        forget_idxs=forget_idxs,\n",
    "        retain_idxs=retain_idxs,\n",
    "        synthetic_dataset=synthetic_dataset,\n",
    "        device=device,\n",
    "        save_path='./results/comprehensive_evaluation.json'\n",
    "    )\n",
    "\n",
    "    # ===================== 8. IID vs Non-IID 비교 (필요시) =====================\n",
    "    if not args.iid:\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\"IID vs NON-IID COMPARISON\".center(70))\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        # IID 설정으로 한 번 더 실험\n",
    "        args_iid = copy.deepcopy(args)\n",
    "        args_iid.iid = 1\n",
    "        \n",
    "        train_iid, test_iid, _, groups_iid = get_dataset(args_iid)\n",
    "        \n",
    "        datasets_dict = {\n",
    "            'noniid': {\n",
    "                'train_dataset': full_dataset,\n",
    "                'test_dataset': test_dataset,\n",
    "                'forget_idxs': forget_idxs,\n",
    "                'retain_idxs': retain_idxs\n",
    "            },\n",
    "            'iid': {\n",
    "                'train_dataset': train_iid,\n",
    "                'test_dataset': test_iid,\n",
    "                'forget_idxs': groups_iid[forget_client],\n",
    "                'retain_idxs': [idx for i, group in groups_iid.items() \n",
    "                               if i != forget_client for idx in group]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        models_dict = {\n",
    "            'Original': original_model,\n",
    "            'Retrain': retrain_model,\n",
    "            'Finetune': finetune_model\n",
    "        }\n",
    "        \n",
    "        from evaluate_mia import evaluate_iid_vs_noniid\n",
    "        iid_comparison = evaluate_iid_vs_noniid(\n",
    "            models_dict=models_dict,\n",
    "            datasets_dict=datasets_dict,\n",
    "            device=device,\n",
    "            save_path='./results/iid_vs_noniid_comparison.json'\n",
    "        )\n",
    "\n",
    "    # ===================== 9. 최종 결과 요약 =====================\n",
    "    end_time = time.time()\n",
    "    total_experiment_time = end_time - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"FINAL EXPERIMENT SUMMARY\".center(70))\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    print(f\"\\nDataset Summary:\")\n",
    "    print(f\"   Total Training Data: {len(full_dataset):,}\")\n",
    "    print(f\"   Forget Set Size: {len(forget_idxs):,}\")\n",
    "    print(f\"   Retain Set Size: {len(retain_idxs):,}\")\n",
    "    print(f\"   Test Set Size: {len(test_dataset):,}\")\n",
    "    print(f\"   Generated Synthetic Data: {len(synthetic_images):,}\")\n",
    "    \n",
    "    print(f\"\\nApproach Summary:\")\n",
    "    print(f\"   Source-Free: ✓ (No direct forget data access)\")\n",
    "    print(f\"   FedEraser Integration: ✓ (Delta weight combination)\")\n",
    "    print(f\"   IID Unseen Data: ✓ (Matching forget distribution)\")\n",
    "    print(f\"   Synthetic Generation: ✓ (GAN-based data synthesis)\")\n",
    "    \n",
    "    print(f\"\\nTiming Analysis:\")\n",
    "    print(f\"   Standard FL:       {fedavg_time:8.2f}s\")\n",
    "    print(f\"   Unlearning Process: {unlearning_time:8.2f}s\")\n",
    "    print(f\"     └── Generation:  {generation_time:8.2f}s\")\n",
    "    print(f\"   Retrain: {retrain_time:8.2f}s\")\n",
    "    print(f\"   Total Experiment:   {total_experiment_time:8.2f}s\")\n",
    "    \n",
    "    print(f\"\\nPerformance Comparison:\")\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        print(f\"   {model_name:10} | Test: {results['test_accuracy']:.3f} | \"\n",
    "              f\"Retain: {results['retain_accuracy']:.3f} | \"\n",
    "              f\"Forget: {results['forget_accuracy']:.3f} | \"\n",
    "              f\"MIA: {results['mia_auc']:.3f}\")\n",
    "\n",
    "\n",
    "    # ===================== 10. MIA 평가 (기존 형식 유지) =====================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"MEMBERSHIP INFERENCE ATTACK EVALUATION\".center(70))\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    all_idxs = set(range(len(full_dataset)))\n",
    "    non_member_candidates = list(all_idxs - set(forget_idxs))\n",
    "    \n",
    "    # Original Model MIA 평가\n",
    "    print(f\"\\n[MIA] Original Model (Before Unlearning):\")\n",
    "    mia_result_before = evaluate_mia(\n",
    "        model=original_model,\n",
    "        dataset=full_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        forget_idxs=forget_idxs,\n",
    "        retain_idxs=test_idxs,\n",
    "        shadow_idxs=np.random.choice(non_member_candidates, len(forget_idxs), replace=False),\n",
    "        device=device,\n",
    "        save_path=\"./mia_result_before.json\"\n",
    "    )\n",
    "    \n",
    "    # Retrain Model MIA 평가\n",
    "    print(f\"\\n[MIA] Retrain Model (Gold Standard):\")\n",
    "    mia_retrain_after = evaluate_mia(\n",
    "        model=retrain_model,\n",
    "        dataset=full_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        forget_idxs=forget_idxs,\n",
    "        retain_idxs=test_idxs,\n",
    "        shadow_idxs=np.random.choice(non_member_candidates, len(forget_idxs), replace=False),\n",
    "        device=device,\n",
    "        save_path=\"./mia_result_retrain.json\"\n",
    "    )\n",
    "    \n",
    "    # Finetune Model MIA 평가\n",
    "    print(f\"\\n[MIA] Finetune Model (Our Method):\")\n",
    "    mia_finetune_after = evaluate_mia(\n",
    "        model=finetune_model,\n",
    "        dataset=full_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        forget_idxs=forget_idxs,\n",
    "        retain_idxs=test_idxs,\n",
    "        shadow_idxs=np.random.choice(non_member_candidates, len(forget_idxs), replace=False),\n",
    "        device=device,\n",
    "        save_path=\"./mia_result_finetune.json\"\n",
    "    )\n",
    "\n",
    "    # ===================== 11. 최종 성능 측정 =====================\n",
    "    original_acc_final, original_loss_final = test_inference(args, original_model, test_dataset)\n",
    "    retrain_acc_final, retrain_loss_final = test_inference(args, retrain_model, test_dataset)\n",
    "    finetune_acc_final, finetune_loss_final = test_inference(args, finetune_model, test_dataset)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_experiment_time = end_time - start_time\n",
    "\n",
    "\n",
    "    return {\n",
    "        'original_acc': original_acc_final, 'retrain_acc': retrain_acc_final, 'finetune_acc': finetune_acc_final,\n",
    "        'original_time': original_total_time, 'retrain_time': retrain_time, 'unlearning_time': unlearning_time,\n",
    "        'generation_time': generation_time, 'finetune_training_time': unlearning_time - generation_time, \n",
    "        'synthetic_count': len(synthetic_images),\n",
    "        'mia_scores': {'original': mia_result_before['auc'], 'retrain': mia_retrain_after['auc'], 'finetune': mia_finetune_after['auc']}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0404126b",
   "metadata": {},
   "source": [
    "# 1. Original Model\n",
    "\n",
    "모든 에포크, 모든 클라이언트와 학습. 언러닝 요청 무시\n",
    "\n",
    "# 2. Retrain Model \n",
    "\n",
    "완전히 새로운 모델로 시작. 처음부터 전체 에포크 동안 forget_client 없이 학습. 이상적인 완전 언러닝의 결과\n",
    "\n",
    "# 3. Finetune Model (Our Method)\n",
    "\n",
    "언러닝 요청 시점의 모델부터 시작. 나머지 에포크 동안 합성 데이터로 복구. 실용적인 언러닝 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3498a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = [\n",
    "    'ipykernel_launcher.py',\n",
    "    '--epochs', '25',\n",
    "    '--num_users', '10',\n",
    "    '--frac', '1.0',\n",
    "    '--local_ep', '10',\n",
    "    '--local_bs', '64',\n",
    "    '--lr', '0.01',\n",
    "    '--momentum', '0.9',\n",
    "    '--dataset', 'cifar',\n",
    "    '--model', 'resnet',\n",
    "    '--iid', '0',\n",
    "    '--gpu', '0',\n",
    "    '--num_classes', '10',\n",
    "    '--dirichlet', '1',\n",
    "    '--alpha', '0.3',\n",
    "    '--load_model', 'None',\n",
    "    '--save_model', './saved_models/model.pth',\n",
    "    '--z_dim', '100',\n",
    "    '--gen_threshold', '0.2',\n",
    "    '--num_gen_samples', '128',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f8646d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n",
      "\n",
      "======================================================================\n",
      "                       EXPERIMENT SETTINGS\n",
      "======================================================================\n",
      "Model           : resnet\n",
      "Dataset         : cifar\n",
      "Num Clients     : 10\n",
      "Fraction        : 1.0\n",
      "IID             : 0\n",
      "dirichlet alpha : 0.3\n",
      "Epoch           : 25\n",
      "Local Epochs    : 10\n",
      "Batch Size      : 64\n",
      "Learning Rate   : 0.01\n",
      "Generator z_dim : 100\n",
      "Disc. Threshold : 0.2\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                         DATASET DISTRIBUTION                         \n",
      "----------------------------------------------------------------------\n",
      "Total Training Data: 45,000\n",
      "Test Data: 10,000\n",
      "Unseen Data Pool: 5,000\n",
      "\n",
      "Federated Learning Setup:\n",
      "   Forget Set Size: 2,339\n",
      "   Retain Set Size: 42,661\n",
      "   IID Unseen Data for Generation: 2,339\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                 PHASE 1: Original FEDERATED LEARNING                 \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original FL Training:  20%|██        | 5/25 [18:53<1:16:24, 229.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Standard FL] Epoch 5/25 | Loss: 0.0953 | Acc: 58.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original FL Training:  40%|████      | 10/25 [38:13<57:03, 228.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Standard FL] Epoch 10/25 | Loss: 0.0426 | Acc: 69.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original FL Training:  48%|████▊     | 12/25 [46:20<50:12, 231.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[UNLEARNING REQUEST] Client 0 requests unlearning at epoch 13\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "            PHASE 2: SOURCE-FREE SYNTHETIC DATA GENERATION            \n",
      "----------------------------------------------------------------------\n",
      "[Source-Free] Server provides IID unseen data to unlearning client...\n",
      "[Source-Free] Client generates synthetic data without direct forget data access...\n",
      "[DCGAN] Using Forget: 2339 + Unseen: 2339 samples with REVERSED distribution mixing\n",
      "[DCGAN] Starting REVERSED distribution mixing training for 200 epochs\n",
      "[Target] Generate images that LOOK LIKE unseen but FOLLOW forget distribution\n",
      "[0/200][0/36] Loss_D: 1.6086 Loss_G: 2.2622 (Adv: 2.2223, Dist: 0.0354, Style: 0.0443) D(x): 0.4683 D(G(z)): 0.5110 / 0.1237\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[0/200][25/36] Loss_D: 1.0594 Loss_G: 4.9595 (Adv: 4.9341, Dist: 0.0127, Style: 0.0382) D(x): 0.6291 D(G(z)): 0.3852 / 0.0087\n",
      "[1/200][0/36] Loss_D: 0.5416 Loss_G: 4.9931 (Adv: 4.9584, Dist: 0.0209, Style: 0.0484) D(x): 0.7540 D(G(z)): 0.2059 / 0.0088\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[1/200][25/36] Loss_D: 0.2522 Loss_G: 5.0488 (Adv: 5.0181, Dist: 0.0183, Style: 0.0431) D(x): 0.8710 D(G(z)): 0.0955 / 0.0076\n",
      "[2/200][0/36] Loss_D: 0.2517 Loss_G: 5.4745 (Adv: 5.4520, Dist: 0.0104, Style: 0.0344) D(x): 0.8764 D(G(z)): 0.0956 / 0.0049\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[2/200][25/36] Loss_D: 0.5408 Loss_G: 3.6645 (Adv: 3.6300, Dist: 0.0224, Style: 0.0465) D(x): 0.7601 D(G(z)): 0.1810 / 0.0305\n",
      "[3/200][0/36] Loss_D: 0.8377 Loss_G: 2.6689 (Adv: 2.6319, Dist: 0.0182, Style: 0.0560) D(x): 0.6823 D(G(z)): 0.2993 / 0.0829\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[3/200][25/36] Loss_D: 0.7292 Loss_G: 3.0342 (Adv: 2.9975, Dist: 0.0134, Style: 0.0601) D(x): 0.7598 D(G(z)): 0.3116 / 0.0669\n",
      "[4/200][0/36] Loss_D: 0.6781 Loss_G: 3.0172 (Adv: 2.9860, Dist: 0.0041, Style: 0.0582) D(x): 0.7345 D(G(z)): 0.2613 / 0.0654\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[4/200][25/36] Loss_D: 0.6831 Loss_G: 3.1034 (Adv: 3.0765, Dist: 0.0051, Style: 0.0487) D(x): 0.6909 D(G(z)): 0.1964 / 0.0616\n",
      "[5/200][0/36] Loss_D: 0.9641 Loss_G: 4.7522 (Adv: 4.7282, Dist: 0.0015, Style: 0.0465) D(x): 0.7073 D(G(z)): 0.3969 / 0.0143\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[5/200][25/36] Loss_D: 0.3901 Loss_G: 3.7753 (Adv: 3.7399, Dist: 0.0114, Style: 0.0594) D(x): 0.8321 D(G(z)): 0.1608 / 0.0288\n",
      "[6/200][0/36] Loss_D: 0.4634 Loss_G: 4.8948 (Adv: 4.8637, Dist: 0.0062, Style: 0.0561) D(x): 0.8023 D(G(z)): 0.1899 / 0.0096\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[6/200][25/36] Loss_D: 0.4028 Loss_G: 3.8757 (Adv: 3.8357, Dist: 0.0024, Style: 0.0777) D(x): 0.7968 D(G(z)): 0.1057 / 0.0256\n",
      "[7/200][0/36] Loss_D: 0.2670 Loss_G: 5.2079 (Adv: 5.1739, Dist: 0.0028, Style: 0.0651) D(x): 0.8848 D(G(z)): 0.0986 / 0.0091\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[7/200][25/36] Loss_D: 0.3794 Loss_G: 5.1717 (Adv: 5.1345, Dist: 0.0078, Style: 0.0666) D(x): 0.8890 D(G(z)): 0.1986 / 0.0109\n",
      "[8/200][0/36] Loss_D: 0.5433 Loss_G: 4.2044 (Adv: 4.1614, Dist: 0.0012, Style: 0.0848) D(x): 0.7506 D(G(z)): 0.1318 / 0.0280\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[8/200][25/36] Loss_D: 0.4115 Loss_G: 4.6353 (Adv: 4.5917, Dist: 0.0127, Style: 0.0744) D(x): 0.8200 D(G(z)): 0.1255 / 0.0176\n",
      "[9/200][0/36] Loss_D: 0.2048 Loss_G: 4.8390 (Adv: 4.8075, Dist: 0.0018, Style: 0.0611) D(x): 0.9116 D(G(z)): 0.0988 / 0.0106\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[9/200][25/36] Loss_D: 1.1044 Loss_G: 2.4129 (Adv: 2.3793, Dist: 0.0006, Style: 0.0666) D(x): 0.4744 D(G(z)): 0.0594 / 0.1691\n",
      "[10/200][0/36] Loss_D: 0.6577 Loss_G: 3.1205 (Adv: 3.0776, Dist: 0.0039, Style: 0.0818) D(x): 0.7585 D(G(z)): 0.2539 / 0.0733\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[10/200][25/36] Loss_D: 0.7210 Loss_G: 2.4728 (Adv: 2.4343, Dist: 0.0012, Style: 0.0759) D(x): 0.6977 D(G(z)): 0.2284 / 0.1095\n",
      "[11/200][0/36] Loss_D: 0.6622 Loss_G: 3.1392 (Adv: 3.1058, Dist: 0.0007, Style: 0.0660) D(x): 0.8124 D(G(z)): 0.3160 / 0.0655\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[11/200][25/36] Loss_D: 0.7331 Loss_G: 4.3536 (Adv: 4.3250, Dist: 0.0034, Style: 0.0537) D(x): 0.7735 D(G(z)): 0.3357 / 0.0173\n",
      "[12/200][0/36] Loss_D: 0.5692 Loss_G: 2.9699 (Adv: 2.9306, Dist: 0.0041, Style: 0.0746) D(x): 0.7235 D(G(z)): 0.1671 / 0.0658\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[12/200][25/36] Loss_D: 0.5377 Loss_G: 5.8804 (Adv: 5.8451, Dist: 0.0045, Style: 0.0662) D(x): 0.8587 D(G(z)): 0.2803 / 0.0047\n",
      "[13/200][0/36] Loss_D: 0.6066 Loss_G: 3.0819 (Adv: 3.0497, Dist: 0.0032, Style: 0.0612) D(x): 0.6489 D(G(z)): 0.0753 / 0.0695\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[13/200][25/36] Loss_D: 0.6978 Loss_G: 3.8971 (Adv: 3.8604, Dist: 0.0024, Style: 0.0708) D(x): 0.7340 D(G(z)): 0.2621 / 0.0282\n",
      "[14/200][0/36] Loss_D: 0.3710 Loss_G: 3.6336 (Adv: 3.5942, Dist: 0.0061, Style: 0.0726) D(x): 0.8120 D(G(z)): 0.1200 / 0.0370\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[14/200][25/36] Loss_D: 0.5275 Loss_G: 4.2849 (Adv: 4.2447, Dist: 0.0042, Style: 0.0761) D(x): 0.8357 D(G(z)): 0.2604 / 0.0202\n",
      "[15/200][0/36] Loss_D: 0.8062 Loss_G: 2.5976 (Adv: 2.5644, Dist: 0.0031, Style: 0.0632) D(x): 0.5667 D(G(z)): 0.0870 / 0.1095\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[15/200][25/36] Loss_D: 0.4512 Loss_G: 3.3678 (Adv: 3.3352, Dist: 0.0006, Style: 0.0646) D(x): 0.8132 D(G(z)): 0.1842 / 0.0511\n",
      "[16/200][0/36] Loss_D: 0.6806 Loss_G: 2.5462 (Adv: 2.4984, Dist: 0.0031, Style: 0.0925) D(x): 0.6463 D(G(z)): 0.1541 / 0.1158\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[16/200][25/36] Loss_D: 0.4476 Loss_G: 3.3316 (Adv: 3.2947, Dist: 0.0004, Style: 0.0734) D(x): 0.8313 D(G(z)): 0.2100 / 0.0484\n",
      "[17/200][0/36] Loss_D: 0.9658 Loss_G: 2.9114 (Adv: 2.8719, Dist: 0.0005, Style: 0.0786) D(x): 0.5644 D(G(z)): 0.1932 / 0.0919\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[17/200][25/36] Loss_D: 0.8624 Loss_G: 3.6663 (Adv: 3.6303, Dist: 0.0020, Style: 0.0700) D(x): 0.7491 D(G(z)): 0.3489 / 0.0418\n",
      "[18/200][0/36] Loss_D: 0.6494 Loss_G: 3.3677 (Adv: 3.3200, Dist: 0.0065, Style: 0.0888) D(x): 0.7724 D(G(z)): 0.2706 / 0.0533\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[18/200][25/36] Loss_D: 1.2082 Loss_G: 2.2491 (Adv: 2.2053, Dist: 0.0058, Style: 0.0816) D(x): 0.5796 D(G(z)): 0.3632 / 0.1506\n",
      "[19/200][0/36] Loss_D: 0.8302 Loss_G: 2.8819 (Adv: 2.8415, Dist: 0.0028, Style: 0.0780) D(x): 0.7280 D(G(z)): 0.3395 / 0.0825\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[19/200][25/36] Loss_D: 0.6171 Loss_G: 3.5942 (Adv: 3.5533, Dist: 0.0025, Style: 0.0794) D(x): 0.8147 D(G(z)): 0.2929 / 0.0421\n",
      "[20/200][0/36] Loss_D: 0.4004 Loss_G: 3.4885 (Adv: 3.4589, Dist: 0.0036, Style: 0.0557) D(x): 0.8579 D(G(z)): 0.1815 / 0.0447\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[20/200][25/36] Loss_D: 0.5201 Loss_G: 4.1568 (Adv: 4.1157, Dist: 0.0016, Style: 0.0807) D(x): 0.8806 D(G(z)): 0.2888 / 0.0232\n",
      "[21/200][0/36] Loss_D: 0.4027 Loss_G: 3.5378 (Adv: 3.4986, Dist: 0.0033, Style: 0.0752) D(x): 0.8934 D(G(z)): 0.2246 / 0.0415\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[21/200][25/36] Loss_D: 0.4362 Loss_G: 3.1461 (Adv: 3.1061, Dist: 0.0040, Style: 0.0759) D(x): 0.8198 D(G(z)): 0.1677 / 0.0657\n",
      "[22/200][0/36] Loss_D: 0.2621 Loss_G: 2.8290 (Adv: 2.7863, Dist: 0.0052, Style: 0.0801) D(x): 0.8628 D(G(z)): 0.0879 / 0.0872\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[22/200][25/36] Loss_D: 0.4808 Loss_G: 2.8094 (Adv: 2.7655, Dist: 0.0047, Style: 0.0833) D(x): 0.7453 D(G(z)): 0.1182 / 0.0859\n",
      "[23/200][0/36] Loss_D: 0.3679 Loss_G: 3.7769 (Adv: 3.7386, Dist: 0.0036, Style: 0.0732) D(x): 0.8735 D(G(z)): 0.1793 / 0.0345\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[23/200][25/36] Loss_D: 0.7295 Loss_G: 2.6189 (Adv: 2.5674, Dist: 0.0075, Style: 0.0955) D(x): 0.6158 D(G(z)): 0.1174 / 0.1125\n",
      "[24/200][0/36] Loss_D: 0.5038 Loss_G: 2.8600 (Adv: 2.8086, Dist: 0.0088, Style: 0.0941) D(x): 0.7143 D(G(z)): 0.1001 / 0.0842\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[24/200][25/36] Loss_D: 0.6690 Loss_G: 3.2643 (Adv: 3.2154, Dist: 0.0065, Style: 0.0913) D(x): 0.7232 D(G(z)): 0.2122 / 0.0740\n",
      "[25/200][0/36] Loss_D: 0.9135 Loss_G: 4.4256 (Adv: 4.3800, Dist: 0.0079, Style: 0.0832) D(x): 0.8622 D(G(z)): 0.4718 / 0.0211\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[25/200][25/36] Loss_D: 0.6462 Loss_G: 3.3625 (Adv: 3.3193, Dist: 0.0031, Style: 0.0833) D(x): 0.7788 D(G(z)): 0.2603 / 0.0566\n",
      "[26/200][0/36] Loss_D: 0.4896 Loss_G: 2.7196 (Adv: 2.6654, Dist: 0.0030, Style: 0.1053) D(x): 0.7279 D(G(z)): 0.0897 / 0.1013\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[26/200][25/36] Loss_D: 0.6523 Loss_G: 3.0294 (Adv: 2.9809, Dist: 0.0055, Style: 0.0916) D(x): 0.7822 D(G(z)): 0.2890 / 0.0715\n",
      "[27/200][0/36] Loss_D: 0.7118 Loss_G: 3.0441 (Adv: 2.9987, Dist: 0.0038, Style: 0.0870) D(x): 0.7904 D(G(z)): 0.3136 / 0.0692\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[27/200][25/36] Loss_D: 0.6378 Loss_G: 2.5162 (Adv: 2.4708, Dist: 0.0034, Style: 0.0875) D(x): 0.6553 D(G(z)): 0.1032 / 0.1263\n",
      "[28/200][0/36] Loss_D: 0.6353 Loss_G: 3.4543 (Adv: 3.3986, Dist: 0.0077, Style: 0.1037) D(x): 0.8019 D(G(z)): 0.2928 / 0.0484\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[28/200][25/36] Loss_D: 0.8923 Loss_G: 3.9259 (Adv: 3.8830, Dist: 0.0077, Style: 0.0783) D(x): 0.9189 D(G(z)): 0.4989 / 0.0325\n",
      "[29/200][0/36] Loss_D: 0.6869 Loss_G: 3.0760 (Adv: 3.0242, Dist: 0.0092, Style: 0.0945) D(x): 0.7570 D(G(z)): 0.2947 / 0.0666\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[29/200][25/36] Loss_D: 0.8498 Loss_G: 3.0871 (Adv: 3.0429, Dist: 0.0068, Style: 0.0816) D(x): 0.8110 D(G(z)): 0.4266 / 0.0634\n",
      "[30/200][0/36] Loss_D: 0.8519 Loss_G: 2.4797 (Adv: 2.4361, Dist: 0.0023, Style: 0.0848) D(x): 0.6711 D(G(z)): 0.3080 / 0.1178\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[30/200][25/36] Loss_D: 0.3878 Loss_G: 2.9364 (Adv: 2.8685, Dist: 0.0059, Style: 0.1300) D(x): 0.8672 D(G(z)): 0.2002 / 0.0733\n",
      "[31/200][0/36] Loss_D: 0.6275 Loss_G: 1.9845 (Adv: 1.9383, Dist: 0.0018, Style: 0.0905) D(x): 0.6828 D(G(z)): 0.1735 / 0.1702\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[31/200][25/36] Loss_D: 0.8853 Loss_G: 2.0199 (Adv: 1.9674, Dist: 0.0041, Style: 0.1010) D(x): 0.6743 D(G(z)): 0.3207 / 0.1813\n",
      "[32/200][0/36] Loss_D: 0.5281 Loss_G: 2.7922 (Adv: 2.7422, Dist: 0.0065, Style: 0.0935) D(x): 0.7229 D(G(z)): 0.1406 / 0.0842\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[32/200][25/36] Loss_D: 0.6578 Loss_G: 3.6591 (Adv: 3.6195, Dist: 0.0026, Style: 0.0767) D(x): 0.8392 D(G(z)): 0.3420 / 0.0415\n",
      "[33/200][0/36] Loss_D: 0.6701 Loss_G: 2.8076 (Adv: 2.7607, Dist: 0.0038, Style: 0.0901) D(x): 0.7347 D(G(z)): 0.2502 / 0.0806\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[33/200][25/36] Loss_D: 0.8669 Loss_G: 1.9112 (Adv: 1.8645, Dist: 0.0060, Style: 0.0876) D(x): 0.6365 D(G(z)): 0.2626 / 0.1847\n",
      "[34/200][0/36] Loss_D: 0.5120 Loss_G: 2.3590 (Adv: 2.3028, Dist: 0.0065, Style: 0.1059) D(x): 0.7117 D(G(z)): 0.1124 / 0.1441\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[34/200][25/36] Loss_D: 0.4794 Loss_G: 2.4165 (Adv: 2.3599, Dist: 0.0060, Style: 0.1071) D(x): 0.7699 D(G(z)): 0.1587 / 0.1209\n",
      "[35/200][0/36] Loss_D: 0.8406 Loss_G: 1.4637 (Adv: 1.4120, Dist: 0.0073, Style: 0.0961) D(x): 0.5714 D(G(z)): 0.1725 / 0.3032\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[35/200][25/36] Loss_D: 0.8155 Loss_G: 2.5724 (Adv: 2.5176, Dist: 0.0092, Style: 0.1004) D(x): 0.7038 D(G(z)): 0.3006 / 0.1147\n",
      "[36/200][0/36] Loss_D: 0.6557 Loss_G: 2.7334 (Adv: 2.6855, Dist: 0.0076, Style: 0.0883) D(x): 0.7261 D(G(z)): 0.2247 / 0.1028\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[36/200][25/36] Loss_D: 0.4392 Loss_G: 2.6399 (Adv: 2.5843, Dist: 0.0067, Style: 0.1044) D(x): 0.8071 D(G(z)): 0.1549 / 0.1083\n",
      "[37/200][0/36] Loss_D: 0.4131 Loss_G: 2.7547 (Adv: 2.7102, Dist: 0.0024, Style: 0.0867) D(x): 0.8146 D(G(z)): 0.1577 / 0.0910\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[37/200][25/36] Loss_D: 0.4802 Loss_G: 2.6120 (Adv: 2.5651, Dist: 0.0059, Style: 0.0877) D(x): 0.7430 D(G(z)): 0.1266 / 0.1060\n",
      "[38/200][0/36] Loss_D: 0.6340 Loss_G: 2.8849 (Adv: 2.8335, Dist: 0.0071, Style: 0.0957) D(x): 0.7896 D(G(z)): 0.2730 / 0.0796\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[38/200][25/36] Loss_D: 0.8797 Loss_G: 1.6427 (Adv: 1.5905, Dist: 0.0072, Style: 0.0973) D(x): 0.5646 D(G(z)): 0.1724 / 0.2463\n",
      "[39/200][0/36] Loss_D: 0.4782 Loss_G: 3.0974 (Adv: 3.0585, Dist: 0.0072, Style: 0.0707) D(x): 0.8081 D(G(z)): 0.1977 / 0.0655\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[39/200][25/36] Loss_D: 0.6080 Loss_G: 2.6577 (Adv: 2.6063, Dist: 0.0042, Style: 0.0986) D(x): 0.7631 D(G(z)): 0.2452 / 0.0956\n",
      "[40/200][0/36] Loss_D: 0.4822 Loss_G: 3.4287 (Adv: 3.3929, Dist: 0.0068, Style: 0.0647) D(x): 0.7057 D(G(z)): 0.0700 / 0.0479\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[40/200][25/36] Loss_D: 0.5780 Loss_G: 2.6409 (Adv: 2.5945, Dist: 0.0042, Style: 0.0886) D(x): 0.7679 D(G(z)): 0.2278 / 0.1006\n",
      "[41/200][0/36] Loss_D: 0.5011 Loss_G: 3.2534 (Adv: 3.2005, Dist: 0.0081, Style: 0.0978) D(x): 0.8853 D(G(z)): 0.2881 / 0.0514\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[41/200][25/36] Loss_D: 0.6779 Loss_G: 2.1995 (Adv: 2.1559, Dist: 0.0058, Style: 0.0813) D(x): 0.8018 D(G(z)): 0.3207 / 0.1502\n",
      "[42/200][0/36] Loss_D: 0.5058 Loss_G: 3.0389 (Adv: 2.9966, Dist: 0.0056, Style: 0.0790) D(x): 0.8917 D(G(z)): 0.2992 / 0.0641\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[42/200][25/36] Loss_D: 0.4882 Loss_G: 2.5990 (Adv: 2.5585, Dist: 0.0064, Style: 0.0745) D(x): 0.8152 D(G(z)): 0.2165 / 0.0973\n",
      "[43/200][0/36] Loss_D: 0.8097 Loss_G: 2.9654 (Adv: 2.9168, Dist: 0.0044, Style: 0.0928) D(x): 0.9297 D(G(z)): 0.4749 / 0.0874\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[43/200][25/36] Loss_D: 1.0699 Loss_G: 3.8422 (Adv: 3.7965, Dist: 0.0065, Style: 0.0851) D(x): 0.7887 D(G(z)): 0.4713 / 0.0346\n",
      "[44/200][0/36] Loss_D: 0.9014 Loss_G: 2.0777 (Adv: 2.0220, Dist: 0.0021, Style: 0.1094) D(x): 0.5403 D(G(z)): 0.1570 / 0.1765\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[44/200][25/36] Loss_D: 0.6414 Loss_G: 2.6651 (Adv: 2.6177, Dist: 0.0042, Style: 0.0906) D(x): 0.7476 D(G(z)): 0.2499 / 0.0954\n",
      "[45/200][0/36] Loss_D: 0.5370 Loss_G: 3.5642 (Adv: 3.5145, Dist: 0.0054, Style: 0.0939) D(x): 0.8928 D(G(z)): 0.3051 / 0.0416\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[45/200][25/36] Loss_D: 0.4251 Loss_G: 3.0880 (Adv: 3.0395, Dist: 0.0078, Style: 0.0893) D(x): 0.8266 D(G(z)): 0.1803 / 0.0667\n",
      "[46/200][0/36] Loss_D: 1.2074 Loss_G: 4.6761 (Adv: 4.6204, Dist: 0.0076, Style: 0.1038) D(x): 0.9032 D(G(z)): 0.5955 / 0.0146\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[46/200][25/36] Loss_D: 0.4006 Loss_G: 2.8022 (Adv: 2.7616, Dist: 0.0003, Style: 0.0809) D(x): 0.8539 D(G(z)): 0.1886 / 0.0879\n",
      "[47/200][0/36] Loss_D: 0.7433 Loss_G: 2.7306 (Adv: 2.6878, Dist: 0.0048, Style: 0.0809) D(x): 0.7197 D(G(z)): 0.2916 / 0.0916\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[47/200][25/36] Loss_D: 0.5484 Loss_G: 2.9983 (Adv: 2.9404, Dist: 0.0044, Style: 0.1114) D(x): 0.8638 D(G(z)): 0.2954 / 0.0687\n",
      "[48/200][0/36] Loss_D: 0.6019 Loss_G: 1.9807 (Adv: 1.9203, Dist: 0.0135, Style: 0.1072) D(x): 0.6878 D(G(z)): 0.1483 / 0.1764\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[48/200][25/36] Loss_D: 0.4477 Loss_G: 3.0051 (Adv: 2.9588, Dist: 0.0061, Style: 0.0866) D(x): 0.7970 D(G(z)): 0.1644 / 0.0687\n",
      "[49/200][0/36] Loss_D: 0.2950 Loss_G: 2.9576 (Adv: 2.9184, Dist: 0.0013, Style: 0.0770) D(x): 0.8867 D(G(z)): 0.1472 / 0.0729\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[49/200][25/36] Loss_D: 1.3982 Loss_G: 4.8725 (Adv: 4.8164, Dist: 0.0097, Style: 0.1026) D(x): 0.9536 D(G(z)): 0.6539 / 0.0155\n",
      "[50/200][0/36] Loss_D: 0.9097 Loss_G: 1.3313 (Adv: 1.2783, Dist: 0.0050, Style: 0.1010) D(x): 0.6168 D(G(z)): 0.2531 / 0.3248\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[50/200][25/36] Loss_D: 0.5033 Loss_G: 2.3835 (Adv: 2.3394, Dist: 0.0047, Style: 0.0833) D(x): 0.7488 D(G(z)): 0.1527 / 0.1173\n",
      "[51/200][0/36] Loss_D: 0.6332 Loss_G: 3.1439 (Adv: 3.0916, Dist: 0.0051, Style: 0.0995) D(x): 0.8209 D(G(z)): 0.3173 / 0.0631\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[51/200][25/36] Loss_D: 0.9574 Loss_G: 3.0584 (Adv: 3.0083, Dist: 0.0026, Style: 0.0976) D(x): 0.7695 D(G(z)): 0.4405 / 0.0685\n",
      "[52/200][0/36] Loss_D: 0.8370 Loss_G: 3.0032 (Adv: 2.9488, Dist: 0.0072, Style: 0.1017) D(x): 0.6184 D(G(z)): 0.2430 / 0.0687\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[52/200][25/36] Loss_D: 0.6180 Loss_G: 3.0834 (Adv: 3.0305, Dist: 0.0021, Style: 0.1038) D(x): 0.7414 D(G(z)): 0.2230 / 0.0680\n",
      "[53/200][0/36] Loss_D: 0.5529 Loss_G: 2.7449 (Adv: 2.7040, Dist: 0.0026, Style: 0.0792) D(x): 0.6946 D(G(z)): 0.1193 / 0.1031\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[53/200][25/36] Loss_D: 0.5534 Loss_G: 2.2538 (Adv: 2.2099, Dist: 0.0068, Style: 0.0810) D(x): 0.7862 D(G(z)): 0.2286 / 0.1359\n",
      "[54/200][0/36] Loss_D: 0.5852 Loss_G: 2.9133 (Adv: 2.8658, Dist: 0.0043, Style: 0.0906) D(x): 0.8145 D(G(z)): 0.2778 / 0.0804\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[54/200][25/36] Loss_D: 0.6522 Loss_G: 2.4891 (Adv: 2.4477, Dist: 0.0048, Style: 0.0780) D(x): 0.6781 D(G(z)): 0.1785 / 0.1170\n",
      "[55/200][0/36] Loss_D: 1.0197 Loss_G: 1.5567 (Adv: 1.5111, Dist: 0.0058, Style: 0.0854) D(x): 0.4716 D(G(z)): 0.0751 / 0.2777\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[55/200][25/36] Loss_D: 0.8457 Loss_G: 1.7164 (Adv: 1.6757, Dist: 0.0029, Style: 0.0786) D(x): 0.5781 D(G(z)): 0.1724 / 0.2355\n",
      "[56/200][0/36] Loss_D: 0.7040 Loss_G: 3.4990 (Adv: 3.4508, Dist: 0.0021, Style: 0.0943) D(x): 0.9233 D(G(z)): 0.4242 / 0.0439\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[56/200][25/36] Loss_D: 0.6801 Loss_G: 2.3434 (Adv: 2.3049, Dist: 0.0048, Style: 0.0723) D(x): 0.6774 D(G(z)): 0.1957 / 0.1330\n",
      "[57/200][0/36] Loss_D: 0.6716 Loss_G: 2.0382 (Adv: 1.9850, Dist: 0.0020, Style: 0.1045) D(x): 0.6603 D(G(z)): 0.1718 / 0.1755\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[57/200][25/36] Loss_D: 0.5530 Loss_G: 2.3616 (Adv: 2.3105, Dist: 0.0028, Style: 0.0994) D(x): 0.7891 D(G(z)): 0.2397 / 0.1315\n",
      "[58/200][0/36] Loss_D: 0.6297 Loss_G: 2.8797 (Adv: 2.8404, Dist: 0.0013, Style: 0.0772) D(x): 0.8049 D(G(z)): 0.3008 / 0.0771\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[58/200][25/36] Loss_D: 1.0999 Loss_G: 2.1687 (Adv: 2.1205, Dist: 0.0022, Style: 0.0944) D(x): 0.4436 D(G(z)): 0.0578 / 0.1742\n",
      "[59/200][0/36] Loss_D: 0.6234 Loss_G: 2.4130 (Adv: 2.3796, Dist: 0.0018, Style: 0.0651) D(x): 0.7954 D(G(z)): 0.2894 / 0.1200\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[59/200][25/36] Loss_D: 0.7177 Loss_G: 2.3148 (Adv: 2.2672, Dist: 0.0018, Style: 0.0933) D(x): 0.7609 D(G(z)): 0.3148 / 0.1326\n",
      "[60/200][0/36] Loss_D: 0.7237 Loss_G: 1.3835 (Adv: 1.3391, Dist: 0.0025, Style: 0.0863) D(x): 0.6841 D(G(z)): 0.2429 / 0.3049\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[60/200][25/36] Loss_D: 0.6244 Loss_G: 2.3157 (Adv: 2.2582, Dist: 0.0026, Style: 0.1125) D(x): 0.7864 D(G(z)): 0.2825 / 0.1356\n",
      "[61/200][0/36] Loss_D: 0.6090 Loss_G: 2.2225 (Adv: 2.1758, Dist: 0.0014, Style: 0.0920) D(x): 0.7580 D(G(z)): 0.2463 / 0.1389\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[61/200][25/36] Loss_D: 0.5434 Loss_G: 2.2811 (Adv: 2.2431, Dist: 0.0007, Style: 0.0754) D(x): 0.7411 D(G(z)): 0.1806 / 0.1353\n",
      "[62/200][0/36] Loss_D: 1.7923 Loss_G: 1.3712 (Adv: 1.3257, Dist: 0.0016, Style: 0.0895) D(x): 0.2723 D(G(z)): 0.0509 / 0.3561\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[62/200][25/36] Loss_D: 0.6684 Loss_G: 2.5628 (Adv: 2.5286, Dist: 0.0011, Style: 0.0674) D(x): 0.8124 D(G(z)): 0.3339 / 0.1033\n",
      "[63/200][0/36] Loss_D: 0.8111 Loss_G: 2.5265 (Adv: 2.4891, Dist: 0.0013, Style: 0.0735) D(x): 0.8402 D(G(z)): 0.4391 / 0.1014\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[63/200][25/36] Loss_D: 0.6552 Loss_G: 1.7618 (Adv: 1.7296, Dist: 0.0014, Style: 0.0630) D(x): 0.7322 D(G(z)): 0.2503 / 0.2045\n",
      "[64/200][0/36] Loss_D: 0.6900 Loss_G: 2.4170 (Adv: 2.3815, Dist: 0.0003, Style: 0.0709) D(x): 0.8393 D(G(z)): 0.3565 / 0.1229\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[64/200][25/36] Loss_D: 0.8042 Loss_G: 0.9026 (Adv: 0.8613, Dist: 0.0013, Style: 0.0814) D(x): 0.5520 D(G(z)): 0.1279 / 0.4748\n",
      "[65/200][0/36] Loss_D: 0.8029 Loss_G: 1.9474 (Adv: 1.9111, Dist: 0.0005, Style: 0.0722) D(x): 0.6529 D(G(z)): 0.2458 / 0.1917\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[65/200][25/36] Loss_D: 0.5993 Loss_G: 2.5862 (Adv: 2.5415, Dist: 0.0023, Style: 0.0870) D(x): 0.8257 D(G(z)): 0.3030 / 0.1011\n",
      "[66/200][0/36] Loss_D: 0.7558 Loss_G: 2.7214 (Adv: 2.6838, Dist: 0.0002, Style: 0.0750) D(x): 0.8682 D(G(z)): 0.4195 / 0.0855\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[66/200][25/36] Loss_D: 0.7046 Loss_G: 2.5526 (Adv: 2.5154, Dist: 0.0015, Style: 0.0728) D(x): 0.8391 D(G(z)): 0.3714 / 0.1025\n",
      "[67/200][0/36] Loss_D: 0.5918 Loss_G: 2.1293 (Adv: 2.0861, Dist: 0.0006, Style: 0.0857) D(x): 0.7340 D(G(z)): 0.2092 / 0.1531\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[67/200][25/36] Loss_D: 0.8515 Loss_G: 1.6537 (Adv: 1.6195, Dist: 0.0005, Style: 0.0679) D(x): 0.5568 D(G(z)): 0.1415 / 0.2551\n",
      "[68/200][0/36] Loss_D: 0.8449 Loss_G: 2.7964 (Adv: 2.7535, Dist: 0.0032, Style: 0.0825) D(x): 0.8078 D(G(z)): 0.4269 / 0.0786\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[68/200][25/36] Loss_D: 0.8618 Loss_G: 1.4345 (Adv: 1.4015, Dist: 0.0005, Style: 0.0655) D(x): 0.5410 D(G(z)): 0.1477 / 0.2897\n",
      "[69/200][0/36] Loss_D: 0.6099 Loss_G: 2.0493 (Adv: 2.0117, Dist: 0.0034, Style: 0.0718) D(x): 0.7564 D(G(z)): 0.2426 / 0.1702\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[69/200][25/36] Loss_D: 0.7151 Loss_G: 1.8019 (Adv: 1.7510, Dist: 0.0019, Style: 0.0999) D(x): 0.6664 D(G(z)): 0.2223 / 0.2038\n",
      "[70/200][0/36] Loss_D: 0.6214 Loss_G: 1.8003 (Adv: 1.7620, Dist: 0.0015, Style: 0.0749) D(x): 0.6723 D(G(z)): 0.1555 / 0.2083\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[70/200][25/36] Loss_D: 0.6582 Loss_G: 2.1749 (Adv: 2.1433, Dist: 0.0021, Style: 0.0611) D(x): 0.7320 D(G(z)): 0.2557 / 0.1472\n",
      "[71/200][0/36] Loss_D: 0.6373 Loss_G: 1.9393 (Adv: 1.9014, Dist: 0.0014, Style: 0.0743) D(x): 0.7292 D(G(z)): 0.2354 / 0.1822\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[71/200][25/36] Loss_D: 0.9467 Loss_G: 2.9696 (Adv: 2.9280, Dist: 0.0017, Style: 0.0816) D(x): 0.8612 D(G(z)): 0.4974 / 0.0753\n",
      "[72/200][0/36] Loss_D: 1.5336 Loss_G: 0.9766 (Adv: 0.9361, Dist: 0.0007, Style: 0.0804) D(x): 0.3031 D(G(z)): 0.1145 / 0.4383\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[72/200][25/36] Loss_D: 0.6807 Loss_G: 2.1296 (Adv: 2.0854, Dist: 0.0069, Style: 0.0813) D(x): 0.7390 D(G(z)): 0.2764 / 0.1599\n",
      "[73/200][0/36] Loss_D: 0.7649 Loss_G: 1.6980 (Adv: 1.6567, Dist: 0.0010, Style: 0.0816) D(x): 0.6259 D(G(z)): 0.2078 / 0.2358\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[73/200][25/36] Loss_D: 0.8111 Loss_G: 2.1994 (Adv: 2.1607, Dist: 0.0030, Style: 0.0745) D(x): 0.7439 D(G(z)): 0.3602 / 0.1413\n",
      "[74/200][0/36] Loss_D: 0.8002 Loss_G: 2.1214 (Adv: 2.0804, Dist: 0.0007, Style: 0.0813) D(x): 0.7108 D(G(z)): 0.3183 / 0.1654\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[74/200][25/36] Loss_D: 0.6932 Loss_G: 1.7528 (Adv: 1.7089, Dist: 0.0006, Style: 0.0872) D(x): 0.7034 D(G(z)): 0.2474 / 0.2185\n",
      "[75/200][0/36] Loss_D: 0.7985 Loss_G: 1.5500 (Adv: 1.5075, Dist: 0.0029, Style: 0.0820) D(x): 0.6049 D(G(z)): 0.1972 / 0.2586\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[75/200][25/36] Loss_D: 0.8104 Loss_G: 1.5868 (Adv: 1.5460, Dist: 0.0025, Style: 0.0791) D(x): 0.6239 D(G(z)): 0.2332 / 0.2514\n",
      "[76/200][0/36] Loss_D: 0.5659 Loss_G: 2.1939 (Adv: 2.1492, Dist: 0.0076, Style: 0.0818) D(x): 0.7443 D(G(z)): 0.1976 / 0.1464\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[76/200][25/36] Loss_D: 1.0017 Loss_G: 1.7329 (Adv: 1.6929, Dist: 0.0015, Style: 0.0785) D(x): 0.5510 D(G(z)): 0.1966 / 0.2592\n",
      "[77/200][0/36] Loss_D: 0.6065 Loss_G: 2.7543 (Adv: 2.7053, Dist: 0.0007, Style: 0.0972) D(x): 0.8547 D(G(z)): 0.3313 / 0.0889\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[77/200][25/36] Loss_D: 0.7905 Loss_G: 1.6383 (Adv: 1.5901, Dist: 0.0006, Style: 0.0958) D(x): 0.6348 D(G(z)): 0.2278 / 0.2385\n",
      "[78/200][0/36] Loss_D: 0.6808 Loss_G: 2.1412 (Adv: 2.1041, Dist: 0.0011, Style: 0.0732) D(x): 0.7945 D(G(z)): 0.3266 / 0.1518\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[78/200][25/36] Loss_D: 0.6452 Loss_G: 1.5641 (Adv: 1.5280, Dist: 0.0019, Style: 0.0704) D(x): 0.7164 D(G(z)): 0.2330 / 0.2493\n",
      "[79/200][0/36] Loss_D: 0.8534 Loss_G: 2.7107 (Adv: 2.6784, Dist: 0.0018, Style: 0.0628) D(x): 0.8374 D(G(z)): 0.4503 / 0.0873\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[79/200][25/36] Loss_D: 0.5910 Loss_G: 2.2950 (Adv: 2.2598, Dist: 0.0016, Style: 0.0688) D(x): 0.7653 D(G(z)): 0.2467 / 0.1271\n",
      "[80/200][0/36] Loss_D: 0.6873 Loss_G: 1.8618 (Adv: 1.8277, Dist: 0.0018, Style: 0.0664) D(x): 0.6952 D(G(z)): 0.2423 / 0.1995\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[80/200][25/36] Loss_D: 0.7005 Loss_G: 1.6184 (Adv: 1.5817, Dist: 0.0002, Style: 0.0732) D(x): 0.7037 D(G(z)): 0.2519 / 0.2408\n",
      "[81/200][0/36] Loss_D: 0.5878 Loss_G: 2.5295 (Adv: 2.4956, Dist: 0.0009, Style: 0.0671) D(x): 0.8119 D(G(z)): 0.2856 / 0.1058\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[81/200][25/36] Loss_D: 1.8232 Loss_G: 3.2382 (Adv: 3.1867, Dist: 0.0053, Style: 0.0976) D(x): 0.8760 D(G(z)): 0.7587 / 0.0618\n",
      "[82/200][0/36] Loss_D: 0.9855 Loss_G: 2.4529 (Adv: 2.4173, Dist: 0.0017, Style: 0.0695) D(x): 0.7403 D(G(z)): 0.4336 / 0.1159\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[82/200][25/36] Loss_D: 0.6333 Loss_G: 2.3567 (Adv: 2.3081, Dist: 0.0006, Style: 0.0966) D(x): 0.7540 D(G(z)): 0.2562 / 0.1278\n",
      "[83/200][0/36] Loss_D: 0.7197 Loss_G: 2.3242 (Adv: 2.2862, Dist: 0.0027, Style: 0.0732) D(x): 0.7596 D(G(z)): 0.3242 / 0.1291\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[83/200][25/36] Loss_D: 0.7506 Loss_G: 1.5901 (Adv: 1.5545, Dist: 0.0016, Style: 0.0696) D(x): 0.6704 D(G(z)): 0.2535 / 0.2579\n",
      "[84/200][0/36] Loss_D: 0.6562 Loss_G: 2.5235 (Adv: 2.4920, Dist: 0.0017, Style: 0.0614) D(x): 0.8988 D(G(z)): 0.3826 / 0.1125\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[84/200][25/36] Loss_D: 0.5283 Loss_G: 2.7346 (Adv: 2.6982, Dist: 0.0020, Style: 0.0708) D(x): 0.7962 D(G(z)): 0.2281 / 0.0849\n",
      "[85/200][0/36] Loss_D: 0.7499 Loss_G: 2.9961 (Adv: 2.9617, Dist: 0.0015, Style: 0.0672) D(x): 0.8857 D(G(z)): 0.4406 / 0.0641\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[85/200][25/36] Loss_D: 0.7078 Loss_G: 2.5616 (Adv: 2.5099, Dist: 0.0008, Style: 0.1027) D(x): 0.8062 D(G(z)): 0.3572 / 0.1002\n",
      "[86/200][0/36] Loss_D: 0.6146 Loss_G: 2.2196 (Adv: 2.1682, Dist: 0.0006, Style: 0.1023) D(x): 0.6741 D(G(z)): 0.1470 / 0.1452\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[86/200][25/36] Loss_D: 0.5918 Loss_G: 2.4218 (Adv: 2.3774, Dist: 0.0024, Style: 0.0865) D(x): 0.8083 D(G(z)): 0.2872 / 0.1177\n",
      "[87/200][0/36] Loss_D: 0.7273 Loss_G: 1.0522 (Adv: 1.0124, Dist: 0.0004, Style: 0.0792) D(x): 0.5844 D(G(z)): 0.1300 / 0.4140\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[87/200][25/36] Loss_D: 0.8586 Loss_G: 1.8850 (Adv: 1.8458, Dist: 0.0010, Style: 0.0776) D(x): 0.6618 D(G(z)): 0.3123 / 0.1943\n",
      "[88/200][0/36] Loss_D: 0.6173 Loss_G: 2.3106 (Adv: 2.2735, Dist: 0.0003, Style: 0.0738) D(x): 0.8392 D(G(z)): 0.3287 / 0.1234\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[88/200][25/36] Loss_D: 0.9814 Loss_G: 2.5621 (Adv: 2.5230, Dist: 0.0023, Style: 0.0758) D(x): 0.8213 D(G(z)): 0.4990 / 0.1028\n",
      "[89/200][0/36] Loss_D: 0.6323 Loss_G: 2.6023 (Adv: 2.5666, Dist: 0.0002, Style: 0.0711) D(x): 0.8499 D(G(z)): 0.3450 / 0.0979\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[89/200][25/36] Loss_D: 0.7448 Loss_G: 2.3966 (Adv: 2.3511, Dist: 0.0020, Style: 0.0890) D(x): 0.8325 D(G(z)): 0.3895 / 0.1262\n",
      "[90/200][0/36] Loss_D: 0.6335 Loss_G: 2.2204 (Adv: 2.1786, Dist: 0.0006, Style: 0.0830) D(x): 0.7221 D(G(z)): 0.2265 / 0.1419\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[90/200][25/36] Loss_D: 0.7856 Loss_G: 2.4508 (Adv: 2.4019, Dist: 0.0010, Style: 0.0968) D(x): 0.7363 D(G(z)): 0.3406 / 0.1136\n",
      "[91/200][0/36] Loss_D: 0.6276 Loss_G: 2.4451 (Adv: 2.4024, Dist: 0.0040, Style: 0.0815) D(x): 0.7551 D(G(z)): 0.2624 / 0.1117\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[91/200][25/36] Loss_D: 0.6211 Loss_G: 1.8916 (Adv: 1.8556, Dist: 0.0009, Style: 0.0711) D(x): 0.7408 D(G(z)): 0.2386 / 0.1813\n",
      "[92/200][0/36] Loss_D: 0.6170 Loss_G: 2.9446 (Adv: 2.8981, Dist: 0.0005, Style: 0.0925) D(x): 0.8549 D(G(z)): 0.3389 / 0.0699\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[92/200][25/36] Loss_D: 0.6497 Loss_G: 2.5165 (Adv: 2.4815, Dist: 0.0003, Style: 0.0697) D(x): 0.8360 D(G(z)): 0.3395 / 0.1138\n",
      "[93/200][0/36] Loss_D: 0.7942 Loss_G: 3.2173 (Adv: 3.1829, Dist: 0.0009, Style: 0.0680) D(x): 0.8770 D(G(z)): 0.4465 / 0.0579\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[93/200][25/36] Loss_D: 0.8137 Loss_G: 2.3663 (Adv: 2.3291, Dist: 0.0005, Style: 0.0738) D(x): 0.7672 D(G(z)): 0.3818 / 0.1211\n",
      "[94/200][0/36] Loss_D: 0.6932 Loss_G: 1.8207 (Adv: 1.7789, Dist: 0.0005, Style: 0.0831) D(x): 0.6852 D(G(z)): 0.2382 / 0.2010\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[94/200][25/36] Loss_D: 0.6104 Loss_G: 2.0118 (Adv: 1.9778, Dist: 0.0059, Style: 0.0620) D(x): 0.7846 D(G(z)): 0.2796 / 0.1652\n",
      "[95/200][0/36] Loss_D: 0.5915 Loss_G: 3.0421 (Adv: 3.0036, Dist: 0.0015, Style: 0.0755) D(x): 0.8558 D(G(z)): 0.3236 / 0.0715\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[95/200][25/36] Loss_D: 0.6190 Loss_G: 2.2139 (Adv: 2.1756, Dist: 0.0026, Style: 0.0741) D(x): 0.7566 D(G(z)): 0.2571 / 0.1393\n",
      "[96/200][0/36] Loss_D: 0.5012 Loss_G: 2.5333 (Adv: 2.4925, Dist: 0.0001, Style: 0.0814) D(x): 0.8425 D(G(z)): 0.2627 / 0.1032\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[96/200][25/36] Loss_D: 0.8226 Loss_G: 2.3389 (Adv: 2.2914, Dist: 0.0026, Style: 0.0926) D(x): 0.7422 D(G(z)): 0.3576 / 0.1314\n",
      "[97/200][0/36] Loss_D: 0.7502 Loss_G: 2.6550 (Adv: 2.6172, Dist: 0.0002, Style: 0.0753) D(x): 0.8527 D(G(z)): 0.4062 / 0.0954\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[97/200][25/36] Loss_D: 0.7387 Loss_G: 2.0642 (Adv: 2.0225, Dist: 0.0023, Style: 0.0810) D(x): 0.6873 D(G(z)): 0.2686 / 0.1607\n",
      "[98/200][0/36] Loss_D: 0.5258 Loss_G: 3.6905 (Adv: 3.6329, Dist: 0.0043, Style: 0.1109) D(x): 0.9150 D(G(z)): 0.3252 / 0.0354\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[98/200][25/36] Loss_D: 0.5189 Loss_G: 2.4586 (Adv: 2.4245, Dist: 0.0014, Style: 0.0668) D(x): 0.8170 D(G(z)): 0.2485 / 0.1118\n",
      "[99/200][0/36] Loss_D: 0.6386 Loss_G: 2.4784 (Adv: 2.4444, Dist: 0.0006, Style: 0.0675) D(x): 0.8562 D(G(z)): 0.3537 / 0.1070\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[99/200][25/36] Loss_D: 0.4077 Loss_G: 2.4700 (Adv: 2.4199, Dist: 0.0073, Style: 0.0930) D(x): 0.8122 D(G(z)): 0.1643 / 0.1086\n",
      "[100/200][0/36] Loss_D: 0.9539 Loss_G: 3.5439 (Adv: 3.4999, Dist: 0.0008, Style: 0.0873) D(x): 0.9278 D(G(z)): 0.5376 / 0.0397\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[100/200][25/36] Loss_D: 0.5297 Loss_G: 2.1577 (Adv: 2.1182, Dist: 0.0019, Style: 0.0770) D(x): 0.7424 D(G(z)): 0.1783 / 0.1473\n",
      "[101/200][0/36] Loss_D: 1.8831 Loss_G: 3.7681 (Adv: 3.7204, Dist: 0.0007, Style: 0.0945) D(x): 0.9246 D(G(z)): 0.7754 / 0.0356\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[101/200][25/36] Loss_D: 0.6866 Loss_G: 2.2222 (Adv: 2.1820, Dist: 0.0026, Style: 0.0779) D(x): 0.7784 D(G(z)): 0.3155 / 0.1502\n",
      "[102/200][0/36] Loss_D: 0.5165 Loss_G: 2.4633 (Adv: 2.4224, Dist: 0.0011, Style: 0.0806) D(x): 0.7815 D(G(z)): 0.2115 / 0.1228\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[102/200][25/36] Loss_D: 0.7842 Loss_G: 2.3366 (Adv: 2.2924, Dist: 0.0023, Style: 0.0861) D(x): 0.8198 D(G(z)): 0.4071 / 0.1216\n",
      "[103/200][0/36] Loss_D: 0.5330 Loss_G: 2.7251 (Adv: 2.6782, Dist: 0.0007, Style: 0.0932) D(x): 0.7986 D(G(z)): 0.2402 / 0.0901\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[103/200][25/36] Loss_D: 0.8299 Loss_G: 2.2504 (Adv: 2.2082, Dist: 0.0021, Style: 0.0823) D(x): 0.7826 D(G(z)): 0.3980 / 0.1339\n",
      "[104/200][0/36] Loss_D: 1.1275 Loss_G: 3.9097 (Adv: 3.8744, Dist: 0.0039, Style: 0.0666) D(x): 0.8049 D(G(z)): 0.5323 / 0.0277\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[104/200][25/36] Loss_D: 0.6546 Loss_G: 2.8478 (Adv: 2.8092, Dist: 0.0009, Style: 0.0763) D(x): 0.8116 D(G(z)): 0.3272 / 0.0815\n",
      "[105/200][0/36] Loss_D: 0.4063 Loss_G: 2.3628 (Adv: 2.3235, Dist: 0.0017, Style: 0.0769) D(x): 0.7728 D(G(z)): 0.1229 / 0.1215\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[105/200][25/36] Loss_D: 0.4357 Loss_G: 2.3181 (Adv: 2.2745, Dist: 0.0010, Style: 0.0862) D(x): 0.7722 D(G(z)): 0.1424 / 0.1270\n",
      "[106/200][0/36] Loss_D: 0.5778 Loss_G: 2.0209 (Adv: 1.9842, Dist: 0.0008, Style: 0.0726) D(x): 0.7356 D(G(z)): 0.2055 / 0.1724\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[106/200][25/36] Loss_D: 0.5705 Loss_G: 1.4608 (Adv: 1.4233, Dist: 0.0011, Style: 0.0740) D(x): 0.6962 D(G(z)): 0.1610 / 0.2813\n",
      "[107/200][0/36] Loss_D: 0.5575 Loss_G: 2.3709 (Adv: 2.3335, Dist: 0.0001, Style: 0.0747) D(x): 0.8443 D(G(z)): 0.2900 / 0.1241\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[107/200][25/36] Loss_D: 1.8604 Loss_G: 4.6442 (Adv: 4.6023, Dist: 0.0011, Style: 0.0827) D(x): 0.8668 D(G(z)): 0.7690 / 0.0165\n",
      "[108/200][0/36] Loss_D: 1.1328 Loss_G: 1.1394 (Adv: 1.0958, Dist: 0.0029, Style: 0.0841) D(x): 0.4215 D(G(z)): 0.1155 / 0.3848\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[108/200][25/36] Loss_D: 0.7650 Loss_G: 2.4848 (Adv: 2.4407, Dist: 0.0068, Style: 0.0813) D(x): 0.8807 D(G(z)): 0.4409 / 0.1072\n",
      "[109/200][0/36] Loss_D: 0.7645 Loss_G: 1.5297 (Adv: 1.4806, Dist: 0.0021, Style: 0.0962) D(x): 0.5723 D(G(z)): 0.1404 / 0.2689\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[109/200][25/36] Loss_D: 0.5192 Loss_G: 2.1326 (Adv: 2.0875, Dist: 0.0011, Style: 0.0890) D(x): 0.7346 D(G(z)): 0.1636 / 0.1539\n",
      "[110/200][0/36] Loss_D: 0.5952 Loss_G: 2.0673 (Adv: 2.0228, Dist: 0.0014, Style: 0.0876) D(x): 0.7524 D(G(z)): 0.2378 / 0.1573\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[110/200][25/36] Loss_D: 0.5575 Loss_G: 2.0309 (Adv: 1.9921, Dist: 0.0011, Style: 0.0767) D(x): 0.7731 D(G(z)): 0.2396 / 0.1571\n",
      "[111/200][0/36] Loss_D: 0.5517 Loss_G: 1.5936 (Adv: 1.5567, Dist: 0.0013, Style: 0.0726) D(x): 0.7105 D(G(z)): 0.1602 / 0.2521\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[111/200][25/36] Loss_D: 0.8980 Loss_G: 2.3970 (Adv: 2.3505, Dist: 0.0010, Style: 0.0920) D(x): 0.6987 D(G(z)): 0.3737 / 0.1116\n",
      "[112/200][0/36] Loss_D: 0.7038 Loss_G: 2.2028 (Adv: 2.1696, Dist: 0.0008, Style: 0.0655) D(x): 0.7910 D(G(z)): 0.3380 / 0.1397\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[112/200][25/36] Loss_D: 0.6186 Loss_G: 1.9486 (Adv: 1.9089, Dist: 0.0012, Style: 0.0782) D(x): 0.8101 D(G(z)): 0.3013 / 0.1760\n",
      "[113/200][0/36] Loss_D: 0.5500 Loss_G: 2.3962 (Adv: 2.3531, Dist: 0.0025, Style: 0.0837) D(x): 0.7634 D(G(z)): 0.2193 / 0.1205\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[113/200][25/36] Loss_D: 0.5261 Loss_G: 1.6246 (Adv: 1.5915, Dist: 0.0014, Style: 0.0649) D(x): 0.7166 D(G(z)): 0.1512 / 0.2350\n",
      "[114/200][0/36] Loss_D: 0.6534 Loss_G: 1.7402 (Adv: 1.7044, Dist: 0.0023, Style: 0.0692) D(x): 0.6232 D(G(z)): 0.1202 / 0.2263\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[114/200][25/36] Loss_D: 0.5515 Loss_G: 2.4294 (Adv: 2.3941, Dist: 0.0001, Style: 0.0704) D(x): 0.8179 D(G(z)): 0.2713 / 0.1099\n",
      "[115/200][0/36] Loss_D: 0.7225 Loss_G: 3.2041 (Adv: 3.1593, Dist: 0.0011, Style: 0.0885) D(x): 0.9336 D(G(z)): 0.4417 / 0.0569\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[115/200][25/36] Loss_D: 0.5641 Loss_G: 3.0444 (Adv: 3.0111, Dist: 0.0002, Style: 0.0664) D(x): 0.9025 D(G(z)): 0.3399 / 0.0656\n",
      "[116/200][0/36] Loss_D: 1.2718 Loss_G: 2.4907 (Adv: 2.4355, Dist: 0.0009, Style: 0.1097) D(x): 0.7657 D(G(z)): 0.5685 / 0.1170\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[116/200][25/36] Loss_D: 0.5146 Loss_G: 2.3250 (Adv: 2.2900, Dist: 0.0024, Style: 0.0676) D(x): 0.7647 D(G(z)): 0.1866 / 0.1308\n",
      "[117/200][0/36] Loss_D: 0.5950 Loss_G: 2.0509 (Adv: 2.0022, Dist: 0.0042, Style: 0.0932) D(x): 0.6973 D(G(z)): 0.1657 / 0.1717\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[117/200][25/36] Loss_D: 0.4393 Loss_G: 2.5158 (Adv: 2.4827, Dist: 0.0004, Style: 0.0657) D(x): 0.7414 D(G(z)): 0.1058 / 0.1087\n",
      "[118/200][0/36] Loss_D: 0.4746 Loss_G: 2.3525 (Adv: 2.3117, Dist: 0.0033, Style: 0.0782) D(x): 0.7092 D(G(z)): 0.0988 / 0.1252\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[118/200][25/36] Loss_D: 0.4462 Loss_G: 2.2685 (Adv: 2.2275, Dist: 0.0021, Style: 0.0798) D(x): 0.8233 D(G(z)): 0.2039 / 0.1341\n",
      "[119/200][0/36] Loss_D: 0.5417 Loss_G: 2.0668 (Adv: 2.0199, Dist: 0.0008, Style: 0.0930) D(x): 0.6499 D(G(z)): 0.0517 / 0.1731\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[119/200][25/36] Loss_D: 0.5039 Loss_G: 2.2397 (Adv: 2.1808, Dist: 0.0012, Style: 0.1166) D(x): 0.8048 D(G(z)): 0.2250 / 0.1377\n",
      "[120/200][0/36] Loss_D: 0.7300 Loss_G: 1.5514 (Adv: 1.5071, Dist: 0.0008, Style: 0.0878) D(x): 0.5473 D(G(z)): 0.0672 / 0.2581\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[120/200][25/36] Loss_D: 0.4965 Loss_G: 2.3670 (Adv: 2.3279, Dist: 0.0008, Style: 0.0773) D(x): 0.7512 D(G(z)): 0.1630 / 0.1241\n",
      "[121/200][0/36] Loss_D: 0.5785 Loss_G: 1.7580 (Adv: 1.7176, Dist: 0.0021, Style: 0.0787) D(x): 0.7144 D(G(z)): 0.1912 / 0.2085\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[121/200][25/36] Loss_D: 0.5094 Loss_G: 2.0084 (Adv: 1.9694, Dist: 0.0006, Style: 0.0773) D(x): 0.6942 D(G(z)): 0.1049 / 0.1644\n",
      "[122/200][0/36] Loss_D: 1.0411 Loss_G: 2.0822 (Adv: 2.0415, Dist: 0.0031, Style: 0.0783) D(x): 0.4917 D(G(z)): 0.1227 / 0.2043\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[122/200][25/36] Loss_D: 0.5801 Loss_G: 1.9993 (Adv: 1.9543, Dist: 0.0019, Style: 0.0881) D(x): 0.6974 D(G(z)): 0.1699 / 0.1769\n",
      "[123/200][0/36] Loss_D: 0.6374 Loss_G: 1.6559 (Adv: 1.6257, Dist: 0.0015, Style: 0.0590) D(x): 0.7085 D(G(z)): 0.2208 / 0.2325\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[123/200][25/36] Loss_D: 0.5516 Loss_G: 1.9721 (Adv: 1.9359, Dist: 0.0016, Style: 0.0709) D(x): 0.7618 D(G(z)): 0.2202 / 0.1701\n",
      "[124/200][0/36] Loss_D: 0.7623 Loss_G: 1.9658 (Adv: 1.9343, Dist: 0.0004, Style: 0.0627) D(x): 0.6955 D(G(z)): 0.2827 / 0.1775\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[124/200][25/36] Loss_D: 1.1679 Loss_G: 1.3777 (Adv: 1.3201, Dist: 0.0006, Style: 0.1145) D(x): 0.5948 D(G(z)): 0.3833 / 0.3561\n",
      "[125/200][0/36] Loss_D: 0.9612 Loss_G: 3.7066 (Adv: 3.6664, Dist: 0.0014, Style: 0.0790) D(x): 0.8567 D(G(z)): 0.4844 / 0.0407\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[125/200][25/36] Loss_D: 0.6306 Loss_G: 1.7826 (Adv: 1.7376, Dist: 0.0032, Style: 0.0867) D(x): 0.7261 D(G(z)): 0.2253 / 0.2116\n",
      "[126/200][0/36] Loss_D: 0.5679 Loss_G: 2.2070 (Adv: 2.1661, Dist: 0.0008, Style: 0.0810) D(x): 0.8078 D(G(z)): 0.2684 / 0.1397\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[126/200][25/36] Loss_D: 0.4447 Loss_G: 2.1845 (Adv: 2.1410, Dist: 0.0008, Style: 0.0862) D(x): 0.7832 D(G(z)): 0.1572 / 0.1465\n",
      "[127/200][0/36] Loss_D: 0.4659 Loss_G: 2.0953 (Adv: 2.0631, Dist: 0.0002, Style: 0.0641) D(x): 0.7533 D(G(z)): 0.1471 / 0.1587\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[127/200][25/36] Loss_D: 0.8562 Loss_G: 1.3756 (Adv: 1.3353, Dist: 0.0047, Style: 0.0759) D(x): 0.4903 D(G(z)): 0.0672 / 0.3314\n",
      "[128/200][0/36] Loss_D: 1.2378 Loss_G: 0.7484 (Adv: 0.7021, Dist: 0.0020, Style: 0.0907) D(x): 0.3737 D(G(z)): 0.0944 / 0.5671\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[128/200][25/36] Loss_D: 0.8545 Loss_G: 2.9082 (Adv: 2.8670, Dist: 0.0028, Style: 0.0797) D(x): 0.8495 D(G(z)): 0.4498 / 0.0821\n",
      "[129/200][0/36] Loss_D: 0.4762 Loss_G: 3.3981 (Adv: 3.3478, Dist: 0.0001, Style: 0.1005) D(x): 0.9387 D(G(z)): 0.3165 / 0.0461\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[129/200][25/36] Loss_D: 0.5655 Loss_G: 2.1866 (Adv: 2.1500, Dist: 0.0010, Style: 0.0722) D(x): 0.8037 D(G(z)): 0.2634 / 0.1463\n",
      "[130/200][0/36] Loss_D: 0.7282 Loss_G: 2.2055 (Adv: 2.1628, Dist: 0.0024, Style: 0.0830) D(x): 0.7913 D(G(z)): 0.3565 / 0.1413\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[130/200][25/36] Loss_D: 0.5984 Loss_G: 2.1945 (Adv: 2.1506, Dist: 0.0024, Style: 0.0855) D(x): 0.7810 D(G(z)): 0.2671 / 0.1453\n",
      "[131/200][0/36] Loss_D: 0.4551 Loss_G: 2.0784 (Adv: 2.0329, Dist: 0.0041, Style: 0.0869) D(x): 0.7684 D(G(z)): 0.1490 / 0.1631\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[131/200][25/36] Loss_D: 0.8703 Loss_G: 1.5057 (Adv: 1.4673, Dist: 0.0002, Style: 0.0768) D(x): 0.4920 D(G(z)): 0.0879 / 0.2788\n",
      "[132/200][0/36] Loss_D: 0.5760 Loss_G: 1.5634 (Adv: 1.5179, Dist: 0.0015, Style: 0.0894) D(x): 0.6993 D(G(z)): 0.1689 / 0.2582\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[132/200][25/36] Loss_D: 0.4225 Loss_G: 2.5903 (Adv: 2.5467, Dist: 0.0013, Style: 0.0859) D(x): 0.8667 D(G(z)): 0.2254 / 0.1011\n",
      "[133/200][0/36] Loss_D: 0.4925 Loss_G: 2.6687 (Adv: 2.6175, Dist: 0.0005, Style: 0.1020) D(x): 0.8233 D(G(z)): 0.2394 / 0.0880\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[133/200][25/36] Loss_D: 0.4059 Loss_G: 2.6889 (Adv: 2.6414, Dist: 0.0018, Style: 0.0933) D(x): 0.8309 D(G(z)): 0.1822 / 0.0961\n",
      "[134/200][0/36] Loss_D: 3.3027 Loss_G: 0.1891 (Adv: 0.1313, Dist: 0.0027, Style: 0.1129) D(x): 0.0946 D(G(z)): 0.0464 / 0.9027\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[134/200][25/36] Loss_D: 0.7055 Loss_G: 1.4057 (Adv: 1.3631, Dist: 0.0007, Style: 0.0844) D(x): 0.6348 D(G(z)): 0.1704 / 0.3024\n",
      "[135/200][0/36] Loss_D: 0.5063 Loss_G: 2.3393 (Adv: 2.2960, Dist: 0.0005, Style: 0.0861) D(x): 0.7824 D(G(z)): 0.2090 / 0.1149\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[135/200][25/36] Loss_D: 0.7064 Loss_G: 1.4861 (Adv: 1.4372, Dist: 0.0004, Style: 0.0974) D(x): 0.6237 D(G(z)): 0.1649 / 0.2715\n",
      "[136/200][0/36] Loss_D: 0.5762 Loss_G: 1.8323 (Adv: 1.7882, Dist: 0.0028, Style: 0.0856) D(x): 0.7910 D(G(z)): 0.2656 / 0.2066\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[136/200][25/36] Loss_D: 0.6705 Loss_G: 1.7366 (Adv: 1.7014, Dist: 0.0018, Style: 0.0686) D(x): 0.6641 D(G(z)): 0.1984 / 0.2133\n",
      "[137/200][0/36] Loss_D: 0.4727 Loss_G: 2.9474 (Adv: 2.9055, Dist: 0.0006, Style: 0.0834) D(x): 0.8813 D(G(z)): 0.2697 / 0.0712\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[137/200][25/36] Loss_D: 0.5513 Loss_G: 2.4935 (Adv: 2.4597, Dist: 0.0021, Style: 0.0654) D(x): 0.8468 D(G(z)): 0.2925 / 0.1037\n",
      "[138/200][0/36] Loss_D: 0.5302 Loss_G: 2.0655 (Adv: 2.0293, Dist: 0.0002, Style: 0.0721) D(x): 0.7753 D(G(z)): 0.2151 / 0.1639\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[138/200][25/36] Loss_D: 0.4800 Loss_G: 2.0503 (Adv: 2.0239, Dist: 0.0007, Style: 0.0522) D(x): 0.7257 D(G(z)): 0.1162 / 0.1630\n",
      "[139/200][0/36] Loss_D: 0.5191 Loss_G: 1.9274 (Adv: 1.8748, Dist: 0.0020, Style: 0.1031) D(x): 0.7116 D(G(z)): 0.1416 / 0.1847\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[139/200][25/36] Loss_D: 0.7071 Loss_G: 3.6902 (Adv: 3.6531, Dist: 0.0029, Style: 0.0711) D(x): 0.9276 D(G(z)): 0.4361 / 0.0331\n",
      "[140/200][0/36] Loss_D: 0.7570 Loss_G: 3.1208 (Adv: 3.0692, Dist: 0.0015, Style: 0.1017) D(x): 0.7990 D(G(z)): 0.3759 / 0.0644\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[140/200][25/36] Loss_D: 0.9824 Loss_G: 1.8317 (Adv: 1.7841, Dist: 0.0024, Style: 0.0928) D(x): 0.5753 D(G(z)): 0.2550 / 0.2130\n",
      "[141/200][0/36] Loss_D: 0.7374 Loss_G: 1.6748 (Adv: 1.6173, Dist: 0.0017, Style: 0.1134) D(x): 0.5683 D(G(z)): 0.0907 / 0.2564\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[141/200][25/36] Loss_D: 0.7194 Loss_G: 1.6465 (Adv: 1.6074, Dist: 0.0021, Style: 0.0761) D(x): 0.7195 D(G(z)): 0.2901 / 0.2336\n",
      "[142/200][0/36] Loss_D: 0.5616 Loss_G: 2.4370 (Adv: 2.3982, Dist: 0.0017, Style: 0.0757) D(x): 0.8132 D(G(z)): 0.2761 / 0.1139\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[142/200][25/36] Loss_D: 0.5406 Loss_G: 1.9484 (Adv: 1.9052, Dist: 0.0007, Style: 0.0858) D(x): 0.7144 D(G(z)): 0.1626 / 0.1828\n",
      "[143/200][0/36] Loss_D: 0.4904 Loss_G: 2.2313 (Adv: 2.1935, Dist: 0.0012, Style: 0.0743) D(x): 0.8362 D(G(z)): 0.2425 / 0.1457\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[143/200][25/36] Loss_D: 0.6054 Loss_G: 3.2581 (Adv: 3.2172, Dist: 0.0009, Style: 0.0809) D(x): 0.9124 D(G(z)): 0.3742 / 0.0529\n",
      "[144/200][0/36] Loss_D: 1.0396 Loss_G: 3.4328 (Adv: 3.4007, Dist: 0.0018, Style: 0.0624) D(x): 0.9108 D(G(z)): 0.5471 / 0.0569\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[144/200][25/36] Loss_D: 0.5334 Loss_G: 2.2023 (Adv: 2.1560, Dist: 0.0001, Style: 0.0924) D(x): 0.6822 D(G(z)): 0.0923 / 0.1502\n",
      "[145/200][0/36] Loss_D: 0.5672 Loss_G: 2.4479 (Adv: 2.4110, Dist: 0.0007, Style: 0.0732) D(x): 0.7231 D(G(z)): 0.1784 / 0.1265\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[145/200][25/36] Loss_D: 0.6065 Loss_G: 2.5158 (Adv: 2.4796, Dist: 0.0007, Style: 0.0717) D(x): 0.9032 D(G(z)): 0.3531 / 0.1117\n",
      "[146/200][0/36] Loss_D: 0.4653 Loss_G: 2.5751 (Adv: 2.5313, Dist: 0.0008, Style: 0.0870) D(x): 0.8234 D(G(z)): 0.2179 / 0.1009\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[146/200][25/36] Loss_D: 0.5706 Loss_G: 2.7030 (Adv: 2.6634, Dist: 0.0042, Style: 0.0749) D(x): 0.8279 D(G(z)): 0.2888 / 0.0915\n",
      "[147/200][0/36] Loss_D: 0.3657 Loss_G: 2.8277 (Adv: 2.7915, Dist: 0.0010, Style: 0.0713) D(x): 0.8463 D(G(z)): 0.1675 / 0.0818\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[147/200][25/36] Loss_D: 0.7823 Loss_G: 2.4300 (Adv: 2.3876, Dist: 0.0010, Style: 0.0838) D(x): 0.7540 D(G(z)): 0.3380 / 0.1205\n",
      "[148/200][0/36] Loss_D: 0.5052 Loss_G: 2.1471 (Adv: 2.1166, Dist: 0.0009, Style: 0.0601) D(x): 0.7862 D(G(z)): 0.2026 / 0.1538\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[148/200][25/36] Loss_D: 0.5085 Loss_G: 1.8482 (Adv: 1.8084, Dist: 0.0012, Style: 0.0784) D(x): 0.7037 D(G(z)): 0.1152 / 0.2023\n",
      "[149/200][0/36] Loss_D: 0.3965 Loss_G: 2.3702 (Adv: 2.3309, Dist: 0.0019, Style: 0.0766) D(x): 0.8216 D(G(z)): 0.1648 / 0.1311\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[149/200][25/36] Loss_D: 0.7063 Loss_G: 1.6788 (Adv: 1.6379, Dist: 0.0035, Style: 0.0782) D(x): 0.5818 D(G(z)): 0.0951 / 0.2325\n",
      "[150/200][0/36] Loss_D: 0.4545 Loss_G: 2.2839 (Adv: 2.2495, Dist: 0.0012, Style: 0.0677) D(x): 0.8389 D(G(z)): 0.2217 / 0.1346\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[150/200][25/36] Loss_D: 0.5497 Loss_G: 2.2147 (Adv: 2.1720, Dist: 0.0005, Style: 0.0848) D(x): 0.6786 D(G(z)): 0.1197 / 0.1538\n",
      "[151/200][0/36] Loss_D: 0.4170 Loss_G: 2.1514 (Adv: 2.1103, Dist: 0.0003, Style: 0.0820) D(x): 0.8368 D(G(z)): 0.1966 / 0.1480\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[151/200][25/36] Loss_D: 0.6977 Loss_G: 1.4667 (Adv: 1.4217, Dist: 0.0005, Style: 0.0897) D(x): 0.5634 D(G(z)): 0.0665 / 0.2855\n",
      "[152/200][0/36] Loss_D: 0.5176 Loss_G: 2.9907 (Adv: 2.9516, Dist: 0.0011, Style: 0.0772) D(x): 0.9388 D(G(z)): 0.3342 / 0.0716\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[152/200][25/36] Loss_D: 0.5189 Loss_G: 1.4221 (Adv: 1.3779, Dist: 0.0005, Style: 0.0879) D(x): 0.7204 D(G(z)): 0.1504 / 0.2968\n",
      "[153/200][0/36] Loss_D: 0.3464 Loss_G: 2.8148 (Adv: 2.7680, Dist: 0.0003, Style: 0.0932) D(x): 0.8701 D(G(z)): 0.1752 / 0.0819\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[153/200][25/36] Loss_D: 0.4154 Loss_G: 2.3519 (Adv: 2.3147, Dist: 0.0012, Style: 0.0733) D(x): 0.8397 D(G(z)): 0.1977 / 0.1258\n",
      "[154/200][0/36] Loss_D: 0.6672 Loss_G: 3.7354 (Adv: 3.7007, Dist: 0.0012, Style: 0.0682) D(x): 0.9580 D(G(z)): 0.4325 / 0.0329\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[154/200][25/36] Loss_D: 0.9465 Loss_G: 3.3905 (Adv: 3.3517, Dist: 0.0009, Style: 0.0765) D(x): 0.9274 D(G(z)): 0.5170 / 0.0508\n",
      "[155/200][0/36] Loss_D: 0.5319 Loss_G: 2.6913 (Adv: 2.6520, Dist: 0.0030, Style: 0.0756) D(x): 0.8620 D(G(z)): 0.2918 / 0.0934\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[155/200][25/36] Loss_D: 0.5581 Loss_G: 1.8079 (Adv: 1.7712, Dist: 0.0009, Style: 0.0724) D(x): 0.7442 D(G(z)): 0.2070 / 0.1993\n",
      "[156/200][0/36] Loss_D: 0.4517 Loss_G: 2.6462 (Adv: 2.6064, Dist: 0.0016, Style: 0.0780) D(x): 0.8607 D(G(z)): 0.2398 / 0.0957\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[156/200][25/36] Loss_D: 0.4514 Loss_G: 2.3623 (Adv: 2.3232, Dist: 0.0006, Style: 0.0777) D(x): 0.8560 D(G(z)): 0.2359 / 0.1214\n",
      "[157/200][0/36] Loss_D: 0.3789 Loss_G: 2.3978 (Adv: 2.3599, Dist: 0.0019, Style: 0.0738) D(x): 0.8172 D(G(z)): 0.1505 / 0.1177\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[157/200][25/36] Loss_D: 0.4748 Loss_G: 3.0643 (Adv: 3.0253, Dist: 0.0008, Style: 0.0773) D(x): 0.8802 D(G(z)): 0.2682 / 0.0665\n",
      "[158/200][0/36] Loss_D: 0.3713 Loss_G: 2.5309 (Adv: 2.4690, Dist: 0.0009, Style: 0.1229) D(x): 0.7519 D(G(z)): 0.0673 / 0.1164\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[158/200][25/36] Loss_D: 0.4571 Loss_G: 2.4694 (Adv: 2.4231, Dist: 0.0034, Style: 0.0893) D(x): 0.7506 D(G(z)): 0.1378 / 0.1136\n",
      "[159/200][0/36] Loss_D: 0.4386 Loss_G: 2.3578 (Adv: 2.3065, Dist: 0.0012, Style: 0.1015) D(x): 0.7546 D(G(z)): 0.1273 / 0.1341\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[159/200][25/36] Loss_D: 0.3778 Loss_G: 2.4802 (Adv: 2.4474, Dist: 0.0015, Style: 0.0641) D(x): 0.8323 D(G(z)): 0.1632 / 0.1092\n",
      "[160/200][0/36] Loss_D: 0.7214 Loss_G: 1.4107 (Adv: 1.3760, Dist: 0.0003, Style: 0.0691) D(x): 0.5656 D(G(z)): 0.0553 / 0.3060\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[160/200][25/36] Loss_D: 0.7927 Loss_G: 3.1809 (Adv: 3.1353, Dist: 0.0048, Style: 0.0865) D(x): 0.8844 D(G(z)): 0.4395 / 0.0615\n",
      "[161/200][0/36] Loss_D: 0.4690 Loss_G: 2.1448 (Adv: 2.1016, Dist: 0.0033, Style: 0.0831) D(x): 0.7607 D(G(z)): 0.1502 / 0.1640\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[161/200][25/36] Loss_D: 0.4172 Loss_G: 2.2859 (Adv: 2.2437, Dist: 0.0015, Style: 0.0829) D(x): 0.8405 D(G(z)): 0.1970 / 0.1417\n",
      "[162/200][0/36] Loss_D: 0.3991 Loss_G: 2.2586 (Adv: 2.2285, Dist: 0.0003, Style: 0.0600) D(x): 0.7347 D(G(z)): 0.0695 / 0.1385\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[162/200][25/36] Loss_D: 0.4535 Loss_G: 2.3184 (Adv: 2.2781, Dist: 0.0000, Style: 0.0806) D(x): 0.7253 D(G(z)): 0.0974 / 0.1324\n",
      "[163/200][0/36] Loss_D: 0.5302 Loss_G: 3.1407 (Adv: 3.1095, Dist: 0.0007, Style: 0.0616) D(x): 0.8953 D(G(z)): 0.3122 / 0.0598\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[163/200][25/36] Loss_D: 0.7728 Loss_G: 1.8229 (Adv: 1.7833, Dist: 0.0006, Style: 0.0787) D(x): 0.6055 D(G(z)): 0.1611 / 0.2391\n",
      "[164/200][0/36] Loss_D: 0.6657 Loss_G: 3.2549 (Adv: 3.2109, Dist: 0.0011, Style: 0.0869) D(x): 0.9211 D(G(z)): 0.3976 / 0.0555\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[164/200][25/36] Loss_D: 0.5289 Loss_G: 1.8972 (Adv: 1.8501, Dist: 0.0012, Style: 0.0930) D(x): 0.7222 D(G(z)): 0.1505 / 0.1995\n",
      "[165/200][0/36] Loss_D: 0.4898 Loss_G: 2.1008 (Adv: 2.0545, Dist: 0.0004, Style: 0.0922) D(x): 0.7528 D(G(z)): 0.1610 / 0.1628\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[165/200][25/36] Loss_D: 0.3655 Loss_G: 2.3547 (Adv: 2.3186, Dist: 0.0055, Style: 0.0666) D(x): 0.7899 D(G(z)): 0.1060 / 0.1362\n",
      "[166/200][0/36] Loss_D: 0.3786 Loss_G: 2.3743 (Adv: 2.3327, Dist: 0.0005, Style: 0.0828) D(x): 0.8263 D(G(z)): 0.1589 / 0.1189\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[166/200][25/36] Loss_D: 0.4940 Loss_G: 2.9014 (Adv: 2.8687, Dist: 0.0030, Style: 0.0625) D(x): 0.8942 D(G(z)): 0.2937 / 0.0726\n",
      "[167/200][0/36] Loss_D: 0.4575 Loss_G: 3.2706 (Adv: 3.2322, Dist: 0.0004, Style: 0.0765) D(x): 0.9380 D(G(z)): 0.3003 / 0.0499\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[167/200][25/36] Loss_D: 0.3582 Loss_G: 3.4030 (Adv: 3.3673, Dist: 0.0018, Style: 0.0696) D(x): 0.9209 D(G(z)): 0.2238 / 0.0446\n",
      "[168/200][0/36] Loss_D: 0.2963 Loss_G: 2.7734 (Adv: 2.7373, Dist: 0.0008, Style: 0.0713) D(x): 0.8478 D(G(z)): 0.1089 / 0.0843\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[168/200][25/36] Loss_D: 0.5082 Loss_G: 1.7827 (Adv: 1.7451, Dist: 0.0044, Style: 0.0708) D(x): 0.7138 D(G(z)): 0.1319 / 0.2164\n",
      "[169/200][0/36] Loss_D: 1.6866 Loss_G: 5.0674 (Adv: 5.0271, Dist: 0.0001, Style: 0.0806) D(x): 0.9861 D(G(z)): 0.7571 / 0.0132\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[169/200][25/36] Loss_D: 0.5554 Loss_G: 2.1547 (Adv: 2.1143, Dist: 0.0006, Style: 0.0803) D(x): 0.7303 D(G(z)): 0.1855 / 0.1529\n",
      "[170/200][0/36] Loss_D: 0.4287 Loss_G: 2.6680 (Adv: 2.6229, Dist: 0.0003, Style: 0.0899) D(x): 0.8065 D(G(z)): 0.1721 / 0.0945\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[170/200][25/36] Loss_D: 0.3959 Loss_G: 2.3712 (Adv: 2.3184, Dist: 0.0013, Style: 0.1044) D(x): 0.8344 D(G(z)): 0.1756 / 0.1301\n",
      "[171/200][0/36] Loss_D: 0.3097 Loss_G: 2.8659 (Adv: 2.8356, Dist: 0.0018, Style: 0.0588) D(x): 0.8675 D(G(z)): 0.1443 / 0.0807\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[171/200][25/36] Loss_D: 0.3701 Loss_G: 2.9981 (Adv: 2.9517, Dist: 0.0009, Style: 0.0920) D(x): 0.9052 D(G(z)): 0.2191 / 0.0660\n",
      "[172/200][0/36] Loss_D: 0.3313 Loss_G: 2.9769 (Adv: 2.9341, Dist: 0.0027, Style: 0.0829) D(x): 0.8957 D(G(z)): 0.1863 / 0.0690\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[172/200][25/36] Loss_D: 0.4664 Loss_G: 3.1971 (Adv: 3.1534, Dist: 0.0003, Style: 0.0870) D(x): 0.9353 D(G(z)): 0.3066 / 0.0548\n",
      "[173/200][0/36] Loss_D: 0.3954 Loss_G: 2.6248 (Adv: 2.5940, Dist: 0.0051, Style: 0.0565) D(x): 0.7789 D(G(z)): 0.1167 / 0.0961\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[173/200][25/36] Loss_D: 0.3996 Loss_G: 2.5261 (Adv: 2.4872, Dist: 0.0025, Style: 0.0752) D(x): 0.7317 D(G(z)): 0.0539 / 0.1157\n",
      "[174/200][0/36] Loss_D: 0.2447 Loss_G: 2.8526 (Adv: 2.8177, Dist: 0.0020, Style: 0.0678) D(x): 0.9377 D(G(z)): 0.1567 / 0.0743\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[174/200][25/36] Loss_D: 0.7283 Loss_G: 3.1779 (Adv: 3.1422, Dist: 0.0005, Style: 0.0711) D(x): 0.7387 D(G(z)): 0.2993 / 0.0693\n",
      "[175/200][0/36] Loss_D: 0.3625 Loss_G: 2.6152 (Adv: 2.5616, Dist: 0.0003, Style: 0.1068) D(x): 0.8027 D(G(z)): 0.1124 / 0.1012\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[175/200][25/36] Loss_D: 1.7233 Loss_G: 4.4604 (Adv: 4.4276, Dist: 0.0009, Style: 0.0647) D(x): 0.9446 D(G(z)): 0.7392 / 0.0257\n",
      "[176/200][0/36] Loss_D: 0.6567 Loss_G: 3.1198 (Adv: 3.0805, Dist: 0.0002, Style: 0.0784) D(x): 0.8115 D(G(z)): 0.3167 / 0.0767\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[176/200][25/36] Loss_D: 0.4750 Loss_G: 2.6961 (Adv: 2.6516, Dist: 0.0026, Style: 0.0863) D(x): 0.9128 D(G(z)): 0.2876 / 0.0946\n",
      "[177/200][0/36] Loss_D: 0.4122 Loss_G: 2.4606 (Adv: 2.4211, Dist: 0.0007, Style: 0.0783) D(x): 0.7936 D(G(z)): 0.1459 / 0.1150\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[177/200][25/36] Loss_D: 0.6317 Loss_G: 1.6688 (Adv: 1.6212, Dist: 0.0014, Style: 0.0938) D(x): 0.6342 D(G(z)): 0.1261 / 0.2450\n",
      "[178/200][0/36] Loss_D: 0.4487 Loss_G: 2.5860 (Adv: 2.5452, Dist: 0.0015, Style: 0.0803) D(x): 0.8855 D(G(z)): 0.2597 / 0.1001\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[178/200][25/36] Loss_D: 0.3867 Loss_G: 2.0058 (Adv: 1.9651, Dist: 0.0006, Style: 0.0809) D(x): 0.7694 D(G(z)): 0.1001 / 0.1788\n",
      "[179/200][0/36] Loss_D: 0.3857 Loss_G: 2.5673 (Adv: 2.5385, Dist: 0.0004, Style: 0.0573) D(x): 0.8084 D(G(z)): 0.1425 / 0.1026\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[179/200][25/36] Loss_D: 0.4483 Loss_G: 2.4151 (Adv: 2.3782, Dist: 0.0020, Style: 0.0718) D(x): 0.8380 D(G(z)): 0.2197 / 0.1154\n",
      "[180/200][0/36] Loss_D: 0.5220 Loss_G: 3.5961 (Adv: 3.5570, Dist: 0.0016, Style: 0.0765) D(x): 0.9002 D(G(z)): 0.3129 / 0.0375\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[180/200][25/36] Loss_D: 0.3404 Loss_G: 2.7836 (Adv: 2.7445, Dist: 0.0015, Style: 0.0766) D(x): 0.8725 D(G(z)): 0.1697 / 0.0806\n",
      "[181/200][0/36] Loss_D: 0.2631 Loss_G: 3.0802 (Adv: 3.0439, Dist: 0.0007, Style: 0.0718) D(x): 0.8900 D(G(z)): 0.1269 / 0.0681\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[181/200][25/36] Loss_D: 0.4783 Loss_G: 2.7815 (Adv: 2.7392, Dist: 0.0004, Style: 0.0842) D(x): 0.8705 D(G(z)): 0.2622 / 0.0903\n",
      "[182/200][0/36] Loss_D: 0.2297 Loss_G: 2.7803 (Adv: 2.7387, Dist: 0.0010, Style: 0.0822) D(x): 0.8760 D(G(z)): 0.0863 / 0.0856\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[182/200][25/36] Loss_D: 0.3208 Loss_G: 3.1125 (Adv: 3.0685, Dist: 0.0023, Style: 0.0856) D(x): 0.8730 D(G(z)): 0.1511 / 0.0689\n",
      "[183/200][0/36] Loss_D: 0.3422 Loss_G: 2.3261 (Adv: 2.2876, Dist: 0.0005, Style: 0.0764) D(x): 0.8035 D(G(z)): 0.1029 / 0.1308\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[183/200][25/36] Loss_D: 0.3704 Loss_G: 2.5337 (Adv: 2.4895, Dist: 0.0057, Style: 0.0827) D(x): 0.8366 D(G(z)): 0.1569 / 0.1061\n",
      "[184/200][0/36] Loss_D: 0.2854 Loss_G: 2.8681 (Adv: 2.8382, Dist: 0.0033, Style: 0.0565) D(x): 0.8931 D(G(z)): 0.1468 / 0.0776\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[184/200][25/36] Loss_D: 2.8321 Loss_G: 4.4136 (Adv: 4.3626, Dist: 0.0003, Style: 0.1017) D(x): 0.8952 D(G(z)): 0.8648 / 0.0437\n",
      "[185/200][0/36] Loss_D: 1.7750 Loss_G: 0.7876 (Adv: 0.7359, Dist: 0.0018, Style: 0.1015) D(x): 0.2557 D(G(z)): 0.0895 / 0.5540\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[185/200][25/36] Loss_D: 0.4763 Loss_G: 2.3883 (Adv: 2.3595, Dist: 0.0002, Style: 0.0574) D(x): 0.7547 D(G(z)): 0.1464 / 0.1293\n",
      "[186/200][0/36] Loss_D: 0.3812 Loss_G: 3.2395 (Adv: 3.2032, Dist: 0.0013, Style: 0.0711) D(x): 0.8522 D(G(z)): 0.1779 / 0.0555\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[186/200][25/36] Loss_D: 0.3123 Loss_G: 2.7002 (Adv: 2.6614, Dist: 0.0004, Style: 0.0772) D(x): 0.8403 D(G(z)): 0.1161 / 0.0908\n",
      "[187/200][0/36] Loss_D: 0.4176 Loss_G: 2.0602 (Adv: 2.0221, Dist: 0.0004, Style: 0.0758) D(x): 0.7545 D(G(z)): 0.1008 / 0.1797\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[187/200][25/36] Loss_D: 0.3581 Loss_G: 2.9484 (Adv: 2.9104, Dist: 0.0014, Style: 0.0746) D(x): 0.8085 D(G(z)): 0.1157 / 0.0765\n",
      "[188/200][0/36] Loss_D: 0.3994 Loss_G: 2.1382 (Adv: 2.0936, Dist: 0.0015, Style: 0.0877) D(x): 0.8054 D(G(z)): 0.1503 / 0.1593\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[188/200][25/36] Loss_D: 0.3340 Loss_G: 2.2656 (Adv: 2.2220, Dist: 0.0004, Style: 0.0868) D(x): 0.8193 D(G(z)): 0.1148 / 0.1367\n",
      "[189/200][0/36] Loss_D: 0.3163 Loss_G: 2.8832 (Adv: 2.8469, Dist: 0.0016, Style: 0.0710) D(x): 0.8919 D(G(z)): 0.1708 / 0.0766\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[189/200][25/36] Loss_D: 0.4014 Loss_G: 2.4788 (Adv: 2.4428, Dist: 0.0029, Style: 0.0693) D(x): 0.8324 D(G(z)): 0.1777 / 0.1185\n",
      "[190/200][0/36] Loss_D: 0.3805 Loss_G: 2.0654 (Adv: 2.0181, Dist: 0.0022, Style: 0.0923) D(x): 0.7592 D(G(z)): 0.0783 / 0.1781\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[190/200][25/36] Loss_D: 0.5799 Loss_G: 4.1901 (Adv: 4.1448, Dist: 0.0008, Style: 0.0899) D(x): 0.9595 D(G(z)): 0.3759 / 0.0232\n",
      "[191/200][0/36] Loss_D: 2.7277 Loss_G: 4.8443 (Adv: 4.7964, Dist: 0.0005, Style: 0.0953) D(x): 0.9065 D(G(z)): 0.8017 / 0.0198\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[191/200][25/36] Loss_D: 0.3916 Loss_G: 2.6907 (Adv: 2.6558, Dist: 0.0006, Style: 0.0693) D(x): 0.8471 D(G(z)): 0.1742 / 0.0973\n",
      "[192/200][0/36] Loss_D: 0.2937 Loss_G: 3.0927 (Adv: 3.0541, Dist: 0.0053, Style: 0.0720) D(x): 0.8746 D(G(z)): 0.1366 / 0.0630\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[192/200][25/36] Loss_D: 0.4424 Loss_G: 2.7198 (Adv: 2.6823, Dist: 0.0008, Style: 0.0741) D(x): 0.8631 D(G(z)): 0.2365 / 0.0857\n",
      "[193/200][0/36] Loss_D: 0.2842 Loss_G: 2.7142 (Adv: 2.6806, Dist: 0.0022, Style: 0.0650) D(x): 0.9007 D(G(z)): 0.1526 / 0.0880\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[193/200][25/36] Loss_D: 0.4088 Loss_G: 2.0270 (Adv: 1.9870, Dist: 0.0012, Style: 0.0787) D(x): 0.8018 D(G(z)): 0.1514 / 0.1753\n",
      "[194/200][0/36] Loss_D: 0.2603 Loss_G: 2.6474 (Adv: 2.6037, Dist: 0.0002, Style: 0.0871) D(x): 0.8408 D(G(z)): 0.0748 / 0.1009\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[194/200][25/36] Loss_D: 0.3964 Loss_G: 2.0991 (Adv: 2.0592, Dist: 0.0010, Style: 0.0787) D(x): 0.7593 D(G(z)): 0.0962 / 0.1675\n",
      "[195/200][0/36] Loss_D: 0.2950 Loss_G: 3.1385 (Adv: 3.0916, Dist: 0.0004, Style: 0.0934) D(x): 0.9102 D(G(z)): 0.1685 / 0.0615\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[195/200][25/36] Loss_D: 0.4276 Loss_G: 2.0056 (Adv: 1.9703, Dist: 0.0003, Style: 0.0702) D(x): 0.7266 D(G(z)): 0.0776 / 0.1847\n",
      "[196/200][0/36] Loss_D: 0.6105 Loss_G: 4.4004 (Adv: 4.3508, Dist: 0.0005, Style: 0.0987) D(x): 0.9369 D(G(z)): 0.3705 / 0.0205\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[196/200][25/36] Loss_D: 0.2458 Loss_G: 2.7705 (Adv: 2.7234, Dist: 0.0040, Style: 0.0901) D(x): 0.8860 D(G(z)): 0.1099 / 0.0894\n",
      "[197/200][0/36] Loss_D: 0.3553 Loss_G: 3.0102 (Adv: 2.9620, Dist: 0.0013, Style: 0.0952) D(x): 0.8274 D(G(z)): 0.1380 / 0.0718\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[197/200][25/36] Loss_D: 0.2744 Loss_G: 3.0845 (Adv: 3.0537, Dist: 0.0007, Style: 0.0610) D(x): 0.8816 D(G(z)): 0.1294 / 0.0643\n",
      "[198/200][0/36] Loss_D: 0.3151 Loss_G: 3.1837 (Adv: 3.1336, Dist: 0.0004, Style: 0.0998) D(x): 0.9214 D(G(z)): 0.1935 / 0.0605\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[198/200][25/36] Loss_D: 0.4006 Loss_G: 2.0299 (Adv: 1.9946, Dist: 0.0009, Style: 0.0697) D(x): 0.7692 D(G(z)): 0.1070 / 0.1685\n",
      "[199/200][0/36] Loss_D: 0.2382 Loss_G: 2.4514 (Adv: 2.4139, Dist: 0.0001, Style: 0.0750) D(x): 0.8516 D(G(z)): 0.0682 / 0.1108\n",
      "[DCGAN] Saving REVERSED distribution-mixed sample images...\n",
      "[199/200][25/36] Loss_D: 0.5477 Loss_G: 4.2837 (Adv: 4.2508, Dist: 0.0028, Style: 0.0630) D(x): 0.9636 D(G(z)): 0.3662 / 0.0188\n",
      "[DCGAN] REVERSED Distribution mixing training completed! Final G_loss: 1.7863, D_loss: 0.4215\n",
      "[Result] Generated images should LOOK LIKE unseen but FOLLOW forget distribution patterns\n",
      "[Generation] Target: 2339 images with fixed threshold 0.2\n",
      "[DCGAN Filter] 64 -> 33 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 37 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 34 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 27 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 32 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 35 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 33 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 30 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 32 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 37 images (threshold=0.2)\n",
      "[Round 10] Total collected: 330/2339\n",
      "[DCGAN Filter] 64 -> 37 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 30 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 31 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 35 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 32 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 35 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 35 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 28 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 35 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 39 images (threshold=0.2)\n",
      "[Round 20] Total collected: 667/2339\n",
      "[DCGAN Filter] 64 -> 31 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 37 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 30 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 33 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 29 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 34 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 35 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 38 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 31 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 29 images (threshold=0.2)\n",
      "[Round 30] Total collected: 994/2339\n",
      "[DCGAN Filter] 64 -> 31 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 31 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 27 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 29 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 36 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 34 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 34 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 28 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 33 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 36 images (threshold=0.2)\n",
      "[Round 40] Total collected: 1313/2339\n",
      "[DCGAN Filter] 64 -> 33 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 38 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 35 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 38 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 27 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 33 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 36 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 33 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 35 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 32 images (threshold=0.2)\n",
      "[Round 50] Total collected: 1653/2339\n",
      "[DCGAN Filter] 64 -> 34 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 36 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 33 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 34 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 37 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 28 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 24 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 36 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 34 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 30 images (threshold=0.2)\n",
      "[Round 60] Total collected: 1979/2339\n",
      "[DCGAN Filter] 64 -> 37 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 42 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 32 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 33 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 40 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 40 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 40 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 32 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 37 images (threshold=0.2)\n",
      "[DCGAN Filter] 64 -> 34 images (threshold=0.2)\n",
      "[Round 70] Total collected: 2339/2339\n",
      "[Generation Complete] Final count: 2339\n",
      "[Source-Free] Generated 2,339 synthetic samples in 279.70s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "           PHASE 3: SIMPLIFIED FEDERASER UNLEARNING PROCESS           \n",
      "======================================================================\n",
      "[FedEraser] Saving pre-unlearning weights excluding unlearning client...\n",
      "[FedEraser] Unlearning client training with synthetic data...\n",
      "[Synthetic Update] Training with 2339 synthetic samples\n",
      "[Synthetic Update] Completed with average loss: 0.2924\n",
      "[FedEraser] Unlearning client completed local training with loss: 0.2924\n",
      "[FedEraser] Combining weights...\n",
      "[FedEraser] Weight combination completed\n",
      "[FedEraser] Resuming federated learning without unlearning client...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Post-Unlearning FL:  42%|████▏     | 5/12 [16:07<22:34, 193.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Post-Unlearning FL] Epoch 5/12 | Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Post-Unlearning FL:  83%|████████▎ | 10/12 [32:16<06:27, 193.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Post-Unlearning FL] Epoch 10/12 | Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Post-Unlearning FL: 100%|██████████| 12/12 [38:43<00:00, 193.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "            BASELINE: ORIGINAL MODEL (IGNORING UNLEARNING)            \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original Continue Training: 100%|██████████| 12/12 [40:51<00:00, 204.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "              BASELINE: RETRAIN MODEL (IDEAL UNLEARNING)              \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain FL Training: 100%|██████████| 25/25 [1:20:06<00:00, 192.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "                       COMPREHENSIVE EVALUATION                       \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "========== Comprehensive Model Comparison ==========\n",
      "\n",
      "--- Evaluating Original Model ---\n",
      "[Classification] Original Test Accuracy: 73.52% (7352/10000)\n",
      "[Classification] Original Retain Accuracy: 94.82% (40452/42661)\n",
      "[Classification] Original Forget Accuracy: 99.27% (2322/2339)\n",
      "[Classification] Original Synthetic Accuracy: 4.53% (106/2339)\n",
      "[Summary] Original - Test: 0.735, Retain: 0.948, Forget: 0.993, MIA: 0.569, Time: 14.96s\n",
      "\n",
      "--- Evaluating Retrain Model ---\n",
      "[Classification] Retrain Test Accuracy: 74.09% (7409/10000)\n",
      "[Classification] Retrain Retain Accuracy: 95.66% (40810/42661)\n",
      "[Classification] Retrain Forget Accuracy: 68.88% (1611/2339)\n",
      "[Classification] Retrain Synthetic Accuracy: 4.66% (109/2339)\n",
      "[Summary] Retrain - Test: 0.741, Retain: 0.957, Forget: 0.689, MIA: 0.674, Time: 14.90s\n",
      "\n",
      "--- Evaluating Finetune Model ---\n",
      "[Classification] Finetune Test Accuracy: 73.50% (7350/10000)\n",
      "[Classification] Finetune Retain Accuracy: 95.08% (40561/42661)\n",
      "[Classification] Finetune Forget Accuracy: 87.35% (2043/2339)\n",
      "[Classification] Finetune Synthetic Accuracy: 4.15% (97/2339)\n",
      "[Summary] Finetune - Test: 0.735, Retain: 0.951, Forget: 0.873, MIA: 0.571, Time: 14.97s\n",
      "\n",
      "==== Final Comparison Summary ====\n",
      "Original   | Test: 0.735 | Retain: 0.948 | Forget: 0.993 | MIA: 0.569\n",
      "Retrain    | Test: 0.741 | Retain: 0.957 | Forget: 0.689 | MIA: 0.674\n",
      "Finetune   | Test: 0.735 | Retain: 0.951 | Forget: 0.873 | MIA: 0.571\n",
      "=====================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                      IID vs NON-IID COMPARISON                       \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "========== IID vs Non-IID Comparison ==========\n",
      "\n",
      "--- IID Setting ---\n",
      "[Classification] IID Original Test Accuracy: 73.52% (7352/10000)\n",
      "[Classification] IID Original Retain Accuracy: 92.94% (37642/40500)\n",
      "[Classification] IID Original Forget Accuracy: 93.04% (4187/4500)\n",
      "[Classification] IID Retrain Test Accuracy: 74.09% (7409/10000)\n",
      "[Classification] IID Retrain Retain Accuracy: 92.29% (37376/40500)\n",
      "[Classification] IID Retrain Forget Accuracy: 92.62% (4168/4500)\n",
      "[Classification] IID Finetune Test Accuracy: 73.50% (7350/10000)\n",
      "[Classification] IID Finetune Retain Accuracy: 92.56% (37488/40500)\n",
      "[Classification] IID Finetune Forget Accuracy: 92.58% (4166/4500)\n",
      "\n",
      "IID Summary:\n",
      "  Original: Test=0.735, Retain=0.929, Forget=0.930\n",
      "  Retrain: Test=0.741, Retain=0.923, Forget=0.926\n",
      "  Finetune: Test=0.735, Retain=0.926, Forget=0.926\n",
      "\n",
      "--- NONIID Setting ---\n",
      "[Classification] NONIID Original Test Accuracy: 73.52% (7352/10000)\n",
      "[Classification] NONIID Original Retain Accuracy: 94.82% (40452/42661)\n",
      "[Classification] NONIID Original Forget Accuracy: 99.27% (2322/2339)\n",
      "[Classification] NONIID Retrain Test Accuracy: 74.09% (7409/10000)\n",
      "[Classification] NONIID Retrain Retain Accuracy: 95.66% (40810/42661)\n",
      "[Classification] NONIID Retrain Forget Accuracy: 68.88% (1611/2339)\n",
      "[Classification] NONIID Finetune Test Accuracy: 73.50% (7350/10000)\n",
      "[Classification] NONIID Finetune Retain Accuracy: 95.08% (40561/42661)\n",
      "[Classification] NONIID Finetune Forget Accuracy: 87.35% (2043/2339)\n",
      "\n",
      "NONIID Summary:\n",
      "  Original: Test=0.735, Retain=0.948, Forget=0.993\n",
      "  Retrain: Test=0.741, Retain=0.957, Forget=0.689\n",
      "  Finetune: Test=0.735, Retain=0.951, Forget=0.873\n",
      "===============================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                       FINAL EXPERIMENT SUMMARY                       \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Dataset Summary:\n",
      "   Total Training Data: 45,000\n",
      "   Forget Set Size: 2,339\n",
      "   Retain Set Size: 42,661\n",
      "   Test Set Size: 10,000\n",
      "   Generated Synthetic Data: 2,339\n",
      "\n",
      "Approach Summary:\n",
      "   Source-Free: ✓ (No direct forget data access)\n",
      "   FedEraser Integration: ✓ (Delta weight combination)\n",
      "   IID Unseen Data: ✓ (Matching forget distribution)\n",
      "   Synthetic Generation: ✓ (GAN-based data synthesis)\n",
      "\n",
      "Timing Analysis:\n",
      "   Standard FL:        2780.94s\n",
      "   Unlearning Process:  2329.42s\n",
      "     └── Generation:    279.70s\n",
      "   Retrain:  4806.82s\n",
      "   Total Experiment:   12778.14s\n",
      "\n",
      "Performance Comparison:\n",
      "   Original   | Test: 0.735 | Retain: 0.948 | Forget: 0.993 | MIA: 0.569\n",
      "   Retrain    | Test: 0.741 | Retain: 0.957 | Forget: 0.689 | MIA: 0.674\n",
      "   Finetune   | Test: 0.735 | Retain: 0.951 | Forget: 0.873 | MIA: 0.571\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                MEMBERSHIP INFERENCE ATTACK EVALUATION                \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[MIA] Original Model (Before Unlearning):\n",
      "retain confidence mean: 0.9382334\n",
      "forget confidence mean: 0.9770497\n",
      "evalu retain confidence mean: 0.8636739\n",
      "evalu forget confidence mean: 0.9770497\n",
      "\n",
      "[MIA] Retrain Model (Gold Standard):\n",
      "retain confidence mean: 0.94073194\n",
      "forget confidence mean: 0.83593017\n",
      "evalu retain confidence mean: 0.8584857\n",
      "evalu forget confidence mean: 0.83593017\n",
      "\n",
      "[MIA] Finetune Model (Our Method):\n",
      "retain confidence mean: 0.93214005\n",
      "forget confidence mean: 0.8958677\n",
      "evalu retain confidence mean: 0.8596994\n",
      "evalu forget confidence mean: 0.8958677\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'original_acc_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 429\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[MIA] Finetune Model (Our Method):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m mia_finetune_after \u001b[38;5;241m=\u001b[39m evaluate_mia(\n\u001b[1;32m    418\u001b[0m     model\u001b[38;5;241m=\u001b[39mfinetune_model,\n\u001b[1;32m    419\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mfull_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./mia_result_finetune.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m )\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43moriginal_acc_final\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: retrain_acc_final, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetune_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: finetune_acc_final,\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_time\u001b[39m\u001b[38;5;124m'\u001b[39m: original_total_time, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrain_time\u001b[39m\u001b[38;5;124m'\u001b[39m: retrain_time, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munlearning_time\u001b[39m\u001b[38;5;124m'\u001b[39m: unlearning_time,\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration_time\u001b[39m\u001b[38;5;124m'\u001b[39m: generation_time, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetune_training_time\u001b[39m\u001b[38;5;124m'\u001b[39m: unlearning_time \u001b[38;5;241m-\u001b[39m generation_time, \n\u001b[1;32m    432\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynthetic_count\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(synthetic_images),\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmia_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m: mia_result_before[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrain\u001b[39m\u001b[38;5;124m'\u001b[39m: mia_retrain_after[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetune\u001b[39m\u001b[38;5;124m'\u001b[39m: mia_finetune_after[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    434\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_acc_final' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
