{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b47a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from torch.utils.data import ConcatDataset #unseen data를 통해서 언러닝 재학습에서 사용.\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference\n",
    "from models import CNNMnist,ResNet18, CNNCifar, Generator, Discriminator, generate_images, filter_images\n",
    "from utils import get_dataset, average_weights, exp_details, create_poisoned_dataset\n",
    "from unlearn import (\n",
    "    train_generator_ungan,\n",
    "    train_gd_ungan,\n",
    "    SyntheticImageDataset, \n",
    "    partition_synthetic_data_iid,\n",
    "    partition_synthetic_data_dirichlet,\n",
    "    get_synthetic_subset\n",
    ")\n",
    "from evaluate_mia import evaluate_mia, comprehensive_evaluation, evaluate_synthetic_classification_accuracy, evaluate_classification_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe0131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "def visualize_real_vs_generated_with_filtering(generator, discriminator, dataset, forget_idxs, \n",
    "                                             z_dim=100, device='cpu', threshold=0.5, num_samples=16):\n",
    "    \"\"\"\n",
    "    실제 이미지, 생성된 이미지, 필터링된 이미지를 모두 비교 시각화\n",
    "    \"\"\"\n",
    "    # 실제 이미지 샘플링\n",
    "    real_images = []\n",
    "    sample_idxs = np.random.choice(forget_idxs, min(num_samples, len(forget_idxs)), replace=False)\n",
    "    \n",
    "    for idx in sample_idxs:\n",
    "        img, _ = dataset[idx]\n",
    "        real_images.append(img)\n",
    "    \n",
    "    real_images = torch.stack(real_images)\n",
    "    \n",
    "    # 더 많은 이미지를 생성해서 필터링 효과를 보여주기\n",
    "    num_generate = num_samples * 2  # 2배 생성해서 필터링\n",
    "    \n",
    "    # 생성된 이미지\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_generate, z_dim, device=device)\n",
    "        generated_images = generator(noise)\n",
    "        \n",
    "        # Discriminator로 품질 평가\n",
    "        d_scores = discriminator(generated_images.to(device))\n",
    "        \n",
    "        # CPU로 이동하고 정규화\n",
    "        generated_images = generated_images.cpu()\n",
    "        generated_images = torch.clamp(generated_images, -1, 1)\n",
    "        generated_images = (generated_images + 1) / 2\n",
    "        \n",
    "        # 필터링 (threshold 이상만 선택)\n",
    "        d_scores = d_scores.cpu().squeeze()\n",
    "        high_quality_mask = d_scores > threshold\n",
    "        \n",
    "        if high_quality_mask.sum() > 0:\n",
    "            filtered_images = generated_images[high_quality_mask]\n",
    "            filtered_scores = d_scores[high_quality_mask]\n",
    "            # 상위 num_samples개만 선택\n",
    "            if len(filtered_images) > num_samples:\n",
    "                top_indices = torch.topk(filtered_scores, num_samples)[1]\n",
    "                filtered_images = filtered_images[top_indices]\n",
    "        else:\n",
    "            # 필터링된 이미지가 없으면 상위 점수 이미지들 선택\n",
    "            top_indices = torch.topk(d_scores, num_samples)[1]\n",
    "            filtered_images = generated_images[top_indices]\n",
    "    \n",
    "    # 실제 이미지 정규화\n",
    "    if real_images.min() < 0:  # 이미 정규화된 경우\n",
    "        real_images = (real_images + 1) / 2\n",
    "    elif real_images.max() > 1:  # 0-255 범위\n",
    "        real_images = real_images / 255.0\n",
    "    \n",
    "    # 3행으로 비교 시각화\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 9))\n",
    "    \n",
    "    # 실제 이미지\n",
    "    real_grid = vutils.make_grid(real_images, nrow=8, normalize=False, padding=2)\n",
    "    real_grid_np = real_grid.permute(1, 2, 0).numpy()\n",
    "    ax1.imshow(real_grid_np, cmap='gray' if real_images.shape[1] == 1 else None)\n",
    "    ax1.set_title('Real Images (Forget Set)', fontsize=14)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # 모든 생성된 이미지 (처음 num_samples개)\n",
    "    all_gen_grid = vutils.make_grid(generated_images[:num_samples], nrow=8, normalize=False, padding=2)\n",
    "    all_gen_grid_np = all_gen_grid.permute(1, 2, 0).numpy()\n",
    "    ax2.imshow(all_gen_grid_np, cmap='gray' if generated_images.shape[1] == 1 else None)\n",
    "    ax2.set_title('All Generated Images', fontsize=14)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # 필터링된 고품질 이미지\n",
    "    filtered_grid = vutils.make_grid(filtered_images, nrow=8, normalize=False, padding=2)\n",
    "    filtered_grid_np = filtered_grid.permute(1, 2, 0).numpy()\n",
    "    ax3.imshow(filtered_grid_np, cmap='gray' if filtered_images.shape[1] == 1 else None)\n",
    "    ax3.set_title(f'High-Quality Filtered Images (D-score > {threshold})', fontsize=14)\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./real_vs_generated_filtered.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Discriminator 점수 통계 출력\n",
    "    print(f\"Discriminator Scores - Mean: {d_scores.mean():.3f}, Std: {d_scores.std():.3f}\")\n",
    "    print(f\"High-quality images (>{threshold}): {high_quality_mask.sum().item()}/{len(d_scores)}\")\n",
    "    print(\"Comparison image saved to: ./real_vs_generated_filtered.png\")\n",
    "\n",
    "\n",
    "def visualize_discriminator_scores(generator, discriminator, z_dim=100, device='cpu', num_samples=100):\n",
    "    \"\"\"\n",
    "    Discriminator 점수 분포를 히스토그램으로 시각화\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_samples, z_dim, device=device)\n",
    "        generated_images = generator(noise)\n",
    "        d_scores = discriminator(generated_images).cpu().squeeze().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(d_scores, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.xlabel('Discriminator Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Discriminator Scores for Generated Images')\n",
    "    plt.axvline(x=0.5, color='red', linestyle='--', label='Threshold (0.5)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('./discriminator_scores_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Discriminator scores - Min: {d_scores.min():.3f}, Max: {d_scores.max():.3f}\")\n",
    "    print(f\"Mean: {d_scores.mean():.3f}, Std: {d_scores.std():.3f}\")\n",
    "    print(\"Discriminator scores distribution saved to: ./discriminator_scores_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ef2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_dataset_to_device(dataset, device):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for x, y in dataset:\n",
    "        images.append(x.to(device))\n",
    "        labels.append(torch.tensor(y).to(device))\n",
    "    return TensorDataset(torch.stack(images), torch.stack(labels))\n",
    "\n",
    "\n",
    "def add_backdoor_trigger(x):\n",
    "    x_bd = x.clone()\n",
    "    x_bd[:, 25:28, 25:28] = 0.9\n",
    "    return x_bd\n",
    "\n",
    "def evaluate_backdoor_asr(model, dataset, target_label, device):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            x, y = dataset[i]\n",
    "            # 백도어 트리거 삽입\n",
    "            x_bd = add_backdoor_trigger(x).to(device)\n",
    "            x_bd = x_bd.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "            output = model(x_bd)\n",
    "            pred = output.argmax(dim=1).item()\n",
    "\n",
    "            total += 1\n",
    "            if pred == target_label:\n",
    "                correct += 1\n",
    "\n",
    "    asr = correct / total\n",
    "    return asr\n",
    "\n",
    "def select_model(args, train_dataset):\n",
    "    if args.model == 'cnn':\n",
    "        if args.dataset == 'cifar':\n",
    "            return CNNCifar(args=args)  # CIFAR-10용 CNN 추가 필요\n",
    "        else:\n",
    "            return CNNMnist(args=args)  # MNIST용 CNN\n",
    "    elif args.model == 'resnet':\n",
    "        return ResNet18(num_classes=args.num_classes)  # CIFAR-10용 ResNet\n",
    "    else:\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b712b",
   "metadata": {},
   "source": [
    "# 전체 플로우\n",
    "\n",
    "## 1. 데이터 준비\n",
    "CIFAR-10 데이터셋\n",
    "Training Set (55,000) → Non-IID로 10개 클라이언트에게 분배\n",
    "\n",
    "Test Set (10,000) → 성능 평가용\n",
    "\n",
    "Unseen Set (5,000) → 모델이 학습하지 않은 깨끗한 데이터\n",
    "\n",
    "## 2. 초기 연합학습 + 언러닝 요청 처리\n",
    "클라이언트 0~9 모두 참여\n",
    "\n",
    "중간에 클라이언트 0이 언러닝 요청 📢\n",
    "\n",
    "서버: \"클라이언트 0 제외하고 계속 진행\"\n",
    "    \n",
    "결과: forget 데이터 영향이 제거된 모델 (하지만 성능 하락하는 문제)\n",
    "\n",
    "## 3. GAN으로 연합학습 + 언러닝 요청 처리\n",
    "목표: forget 데이터를 고품질로 대체할 합성 데이터 생성\n",
    "\n",
    "Generator 훈련: forget 데이터 특징 학습\n",
    "\n",
    "Discriminator 훈련: 진짜/가짜 구분\n",
    "\n",
    "Unseen 데이터 활용: 더 자연스러운 생성\n",
    "\n",
    "결과: forget_size만큼의 고품질 합성 데이터\n",
    "\n",
    "## 4. 성능 복구 연합학습\n",
    "데이터 구성:\n",
    "\n",
    "Retain Set (기존 클라이언트 1~9의 데이터)\n",
    "\n",
    "Synthetic Set (생성된 합성 데이터)\n",
    "\n",
    "연합학습 참여자:\n",
    "\n",
    "클라이언트 1~9 (forget 클라이언트 0은 여전히 제외)\n",
    "\n",
    "각 클라이언트: 기존 retain 데이터 + 할당된 합성 데이터\n",
    "\n",
    "결과: 성능이 복구된 언러닝 모델\n",
    "\n",
    "## 5. 성능 비교평가\n",
    "4가지 데이터셋으로 성능 측정:\n",
    "\n",
    "Original Test Set: 전체적인 모델 성능\n",
    "\n",
    "Retain Set: 남아있는 데이터 성능 \n",
    "\n",
    "Forget Set: 잊혀진 데이터 성능 \n",
    "\n",
    "Synthetic Set: 생성 데이터 품질\n",
    "\n",
    "핵심: Synthetic vs Unseen 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39658942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    args = args_parser()\n",
    "    device = 'cuda' if args.gpu and torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    exp_details(args)\n",
    "\n",
    "    # ===================== 1. 데이터셋 로딩 및 초기화 =====================\n",
    "    train_dataset, test_dataset, unseen_dataset, user_groups = get_dataset(args)\n",
    "    \n",
    "\n",
    "    # full_dataset, user_groups = create_poisoned_dataset(train_dataset, user_groups, args,\n",
    "    #                                                     malicious_client=0,\n",
    "    #                                                     target_label=6,\n",
    "    #                                                     poison_ratio=0.8)\n",
    "\n",
    "    full_dataset = train_dataset  # create_poisoned_dataset 제거\n",
    "\n",
    "\n",
    "\n",
    "    global_model = select_model(args, full_dataset).to(device)\n",
    "    global_model.train()\n",
    "\n",
    "    generator = Generator(z_dim=args.z_dim).to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "\n",
    "    global_weights = global_model.state_dict()\n",
    "    train_loss, train_accuracy = [], []\n",
    "\n",
    "    forget_client = 0\n",
    "    forget_idxs = user_groups[forget_client]\n",
    "    retain_idxs = [i for i in range(len(train_dataset)) if i not in forget_idxs]\n",
    "    test_idxs = np.random.choice(len(test_dataset), len(forget_idxs), replace=False)\n",
    "\n",
    "    # 데이터 수량 균형 - unseen 데이터 준비\n",
    "    forget_size = len(forget_idxs)\n",
    "    unseen_idxs = np.random.choice(len(unseen_dataset), forget_size, replace=False)\n",
    "    unseen_subset = Subset(unseen_dataset, unseen_idxs)\n",
    "    \n",
    "    print(f\"Data sizes - Forget: {forget_size}, Unseen: {len(unseen_idxs)}\")\n",
    "\n",
    "\n",
    "    # ===================== 2. 연합 학습 (FedAvg) =====================\n",
    "    for epoch in tqdm(range(args.epochs), desc='Global Training Rounds'):\n",
    "        print(f'\\n| Global Training Round : {epoch + 1} |')\n",
    "\n",
    "        local_weights, local_losses = [], []\n",
    "        m = max(int(args.frac * args.num_users), 1)\n",
    "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "\n",
    "        for idx in idxs_users:\n",
    "            if idx == forget_client:\n",
    "                continue  # 언러닝 요청자 제거 / 재학습\n",
    "\n",
    "            local_model = LocalUpdate(args=args, dataset=full_dataset, idxs=user_groups[idx])\n",
    "            w, loss = local_model.update_weights(model=copy.deepcopy(global_model), global_round=epoch)\n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(loss)\n",
    "\n",
    "        global_weights = average_weights(local_weights)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        loss_avg = sum(local_losses) / len(local_losses)\n",
    "        acc, _ = test_inference(args, global_model, test_dataset)\n",
    "        train_loss.append(loss_avg)\n",
    "        train_accuracy.append(acc)\n",
    "\n",
    "        print(f\"Training Loss: {loss_avg:.4f} | Train Accuracy: {acc*100:.2f}%\")\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Re_Training Time: {elapsed_time:.2f}초\")\n",
    "    test_acc_before, test_loss_before = test_inference(args, global_model, test_dataset)\n",
    "    print(f\"\\n[Test Before Unlearning] Accuracy: {test_acc_before*100:.2f}% | Loss: {test_loss_before:.4f}\")\n",
    "    \n",
    "\n",
    "    # ===================== 3. 언러닝 전 분류 정확도 평가 =====================\n",
    "    print(\"\\n========== Before Unlearning - Classification Performance ===========\")\n",
    "    before_results = comprehensive_evaluation(\n",
    "        model=global_model,\n",
    "        train_dataset=full_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        forget_idxs=forget_idxs,\n",
    "        retain_idxs=retain_idxs,\n",
    "        synthetic_dataset=None,  # 아직 생성 전\n",
    "        device=device,\n",
    "        save_path=\"./classification_results_before_unlearning.json\"\n",
    "    )\n",
    "\n",
    "    # Unseen 데이터 성능도 측정 (비교 기준)\n",
    "    unseen_acc_before = evaluate_synthetic_classification_accuracy(\n",
    "        global_model, unseen_subset, device, \"Unseen Data (Before Unlearning)\"\n",
    "    )\n",
    "    \n",
    "     \n",
    "    # ===================== 4. MIA 평가 =====================\n",
    "    print(\"[MIA] Evaluating membership inference attack...\")\n",
    "\n",
    "    all_idxs = set(range(len(full_dataset)))\n",
    "    non_member_candidates = list(all_idxs - set(forget_idxs))\n",
    "    #여기에서 쉐도우에는 forget 데이터가 없도록 하기.\n",
    "    mia_result = evaluate_mia(\n",
    "        model=global_model,\n",
    "        dataset=full_dataset,\n",
    "        test_dataset= test_dataset,\n",
    "        forget_idxs=forget_idxs,\n",
    "        retain_idxs=test_idxs,\n",
    "        shadow_idxs=np.random.choice(non_member_candidates, len(forget_idxs), replace=False),\n",
    "        device=device,\n",
    "        save_path=\"./mia_result_before.json\"\n",
    "    )\n",
    "\n",
    "    print(f\"[MIA] AUC: {mia_result['auc']:.4f}\")\n",
    "\n",
    "\n",
    "    # ===================== 5. 합성 데이터 생성 및 시각화 =====================\n",
    "    print(\"\\n[Generating synthetic data...]\")\n",
    "    \n",
    "    # Generator와 Discriminator 함께 훈련 (더 긴 에포크)\n",
    "    generator, discriminator = train_gd_ungan(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        dataset=full_dataset,\n",
    "        retain_idxs=retain_idxs,\n",
    "        forget_idxs=forget_idxs,\n",
    "        device=device,\n",
    "        lambda_adv=1.0,\n",
    "        z_dim=args.z_dim,\n",
    "        batch_size=64,\n",
    "        epochs=30  # GAN 품질 향상\n",
    "    )\n",
    "    \n",
    "    # 합성 데이터 생성\n",
    "    synthetic_images, synthetic_labels = generate_images(\n",
    "        generator=generator,\n",
    "        idxs=forget_idxs,\n",
    "        dataset=full_dataset,\n",
    "        device=device,\n",
    "        z_dim=args.z_dim,\n",
    "        num_generate=forget_size\n",
    "    )\n",
    "    \n",
    "    # Discriminator로 고품질 이미지 필터링\n",
    "    print(\"[Filtering synthetic images with Discriminator...]\")\n",
    "    filtered_images, filtered_labels = filter_images(\n",
    "        discriminator=discriminator,\n",
    "        images=synthetic_images,\n",
    "        labels=synthetic_labels,\n",
    "        threshold=args.gen_threshold,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated {len(synthetic_images)} images, filtered to {len(filtered_images)} high-quality images\")\n",
    "    \n",
    "    # 필터링된 이미지로 데이터셋 생성\n",
    "    if len(filtered_images) > 0:\n",
    "        synthetic_dataset = SyntheticImageDataset(filtered_images, filtered_labels)\n",
    "        use_filtered = True\n",
    "    else:\n",
    "        print(\"[Warning] No images passed discriminator filter, using all generated images\")\n",
    "        synthetic_dataset = SyntheticImageDataset(synthetic_images, synthetic_labels)\n",
    "        use_filtered = False\n",
    "    \n",
    "    # 시각화 (필터링된 이미지 사용)\n",
    "    print(\"[Visualizing real vs synthetic images...]\")\n",
    "    visualize_real_vs_generated_with_filtering(\n",
    "        generator, discriminator, full_dataset, forget_idxs, \n",
    "        args.z_dim, device, args.gen_threshold\n",
    "    )\n",
    "\n",
    "    # ===================== 6. 언러닝 과정: 합성 데이터로 추가 연합학습 =====================\n",
    "    print(\"\\n[Unlearning Process: Federated Learning with Synthetic Data...]\")\n",
    "    \n",
    "    # Retain 데이터와 합성 데이터를 합친 새로운 데이터셋 생성\n",
    "    retain_dataset = Subset(full_dataset, retain_idxs)\n",
    "    combined_dataset = ConcatDataset([retain_dataset, synthetic_dataset])\n",
    "    \n",
    "    print(f\"Combined dataset size: {len(combined_dataset)} (Retain: {len(retain_dataset)}, Synthetic: {len(synthetic_dataset)})\")\n",
    "    \n",
    "    # 새로운 user_groups 구성 (forget_client 제외)\n",
    "    remaining_clients = [i for i in range(args.num_users) if i != forget_client]\n",
    "    \n",
    "    # Retain 데이터를 남은 클라이언트들에게 재분배\n",
    "    retain_user_groups = {}\n",
    "    for client_id in remaining_clients:\n",
    "        retain_user_groups[client_id] = user_groups[client_id]  # 기존 retain 데이터 유지\n",
    "    \n",
    "    # 합성 데이터도 Non-IID로 분배 (Dirichlet 사용)\n",
    "    from utils import partition_data_dirichlet\n",
    "\n",
    "    # 합성 데이터를 Non-IID로 분배\n",
    "    synthetic_labels = [synthetic_dataset[i][1] for i in range(len(synthetic_dataset))]\n",
    "    synthetic_user_groups = partition_synthetic_data_dirichlet(\n",
    "        synthetic_dataset, \n",
    "        num_users=len(remaining_clients), \n",
    "        alpha=args.alpha,  # 동일한 alpha 사용\n",
    "        num_classes=args.num_classes\n",
    "    )\n",
    "\n",
    "    # 언러닝 연합학습\n",
    "    unlearning_epochs = args.epochs  # 절반 에포크\n",
    "    \n",
    "    for epoch in tqdm(range(unlearning_epochs), desc='Unlearning FL Rounds'):\n",
    "        print(f'\\n| Unlearning FL Round : {epoch + 1} |')\n",
    "        \n",
    "        local_weights, local_losses = [], []\n",
    "        m = max(int(args.frac * len(remaining_clients)), 1)\n",
    "        idxs_users = np.random.choice(remaining_clients, m, replace=False)\n",
    "        \n",
    "        for idx in idxs_users:\n",
    "            # Retain 데이터 인덱스\n",
    "            retain_client_idxs = retain_user_groups[idx]\n",
    "            \n",
    "            # 합성 데이터 인덱스 (combined_dataset에서의 위치 조정)\n",
    "            synthetic_client_idx = remaining_clients.index(idx)\n",
    "            synthetic_client_idxs = synthetic_user_groups[synthetic_client_idx]\n",
    "            synthetic_adjusted_idxs = [i + len(retain_dataset) for i in synthetic_client_idxs]\n",
    "            \n",
    "            # 클라이언트의 전체 데이터 인덱스 (retain + synthetic)\n",
    "            client_all_idxs = list(retain_client_idxs) + synthetic_adjusted_idxs\n",
    "            \n",
    "            # 로컬 업데이트\n",
    "            local_model = LocalUpdate(args=args, dataset=combined_dataset, idxs=client_all_idxs)\n",
    "            w, loss = local_model.update_weights(model=copy.deepcopy(global_model), global_round=epoch)\n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(loss)\n",
    "        \n",
    "        # 글로벌 모델 업데이트\n",
    "        global_weights = average_weights(local_weights)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "        \n",
    "        loss_avg = sum(local_losses) / len(local_losses)\n",
    "        acc, _ = test_inference(args, global_model, test_dataset)\n",
    "        \n",
    "        print(f\"Unlearning FL Loss: {loss_avg:.4f} | Test Accuracy: {acc*100:.2f}%\")\n",
    "    \n",
    "    print(\"Unlearning process completed!\")\n",
    "\n",
    "\n",
    "    # ===================== 7. 언러닝 후 분류 정확도 평가 =====================\n",
    "    print(\"\\n========== After Unlearning - Classification Performance ===========\")\n",
    "    after_results = comprehensive_evaluation(\n",
    "        model=global_model,\n",
    "        train_dataset=full_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        forget_idxs=forget_idxs,\n",
    "        retain_idxs=retain_idxs,\n",
    "        synthetic_dataset=None,  # 공정한 비교를 위해 None\n",
    "        device=device,\n",
    "        save_path=\"./classification_results_after_unlearning.json\"\n",
    "    )\n",
    "    \n",
    "    # 언러닝 후 합성 데이터 성능 측정\n",
    "    synthetic_acc_after = evaluate_synthetic_classification_accuracy(\n",
    "        global_model, synthetic_dataset, device, \"Synthetic Data (After Unlearning)\"\n",
    "    )\n",
    "    \n",
    "    # 언러닝 후 Unseen 데이터 성능 측정 (이상적 기준)\n",
    "    unseen_acc_after = evaluate_synthetic_classification_accuracy(\n",
    "        global_model, unseen_subset, device, \"Unseen Data (After Unlearning)\"\n",
    "    )\n",
    "    \n",
    "    # ===================== 8. 언러닝 후 MIA 평가 =====================\n",
    "    print(\"\\n[MIA] Evaluating membership inference attack after unlearning...\")\n",
    "    mia_result_after = evaluate_mia(\n",
    "        model=global_model,\n",
    "        dataset=full_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        forget_idxs=forget_idxs,\n",
    "        retain_idxs=test_idxs,\n",
    "        shadow_idxs=np.random.choice(non_member_candidates, len(forget_idxs), replace=False),\n",
    "        device=device,\n",
    "        save_path=\"./mia_result_after.json\"\n",
    "    )\n",
    "    print(f\"[MIA After] AUC: {mia_result_after['auc']:.4f}\")\n",
    "    \n",
    "    # ===================== 9. 결과 비교 요약 =====================\n",
    "    print(\"\\n========== Classification Performance Comparison ===========\")\n",
    "    print(f\"Original Test Set - Before: {before_results['original_test_accuracy']*100:.2f}% | After: {after_results['original_test_accuracy']*100:.2f}%\")\n",
    "    print(f\"Retain Set - Before: {before_results['retain_set_accuracy']*100:.2f}% | After: {after_results['retain_set_accuracy']*100:.2f}%\")\n",
    "    print(f\"Forget Set - Before: {before_results['forget_set_accuracy']*100:.2f}% | After: {after_results['forget_set_accuracy']*100:.2f}%\")\n",
    "    print(\"============================================================\")\n",
    "    \n",
    "    print(\"\\n========== Replacement Data Quality Comparison ===========\")\n",
    "    print(f\"Unseen Data - Before: {unseen_acc_before*100:.2f}% | After: {unseen_acc_after*100:.2f}%\")\n",
    "    print(f\"Synthetic Data - After: {synthetic_acc_after*100:.2f}%\")\n",
    "    print(f\"Quality Gap (Unseen vs Synthetic): {abs(unseen_acc_after - synthetic_acc_after)*100:.2f}%\")\n",
    "    print(\"============================================================\")\n",
    "    \n",
    "    print(\"\\n========== MIA Attack Comparison ===========\")\n",
    "    print(f\"MIA AUC - Before: {mia_result['auc']:.4f} | After: {mia_result_after['auc']:.4f}\")\n",
    "    print(f\"Privacy Improvement: {(mia_result['auc'] - mia_result_after['auc']):.4f}\")\n",
    "    print(\"============================================================\")\n",
    "    \n",
    "\n",
    "\n",
    "    #torch.save(global_model.state_dict(), args.save_model)\n",
    "    #print(f\"[Saved] model to {args.save_model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3498a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = [\n",
    "    'ipykernel_launcher.py',\n",
    "    '--epochs', '50',\n",
    "    '--num_users', '10',\n",
    "    '--frac', '1.0',\n",
    "    '--local_ep', '10',\n",
    "    '--local_bs', '64',\n",
    "    '--lr', '0.01',\n",
    "    '--momentum', '0.9',\n",
    "    '--dataset', 'cifar',\n",
    "    '--model', 'resnet',\n",
    "    '--iid', '0',\n",
    "    '--gpu', '0',\n",
    "    '--num_classes', '10',\n",
    "    '--dirichlet', '1',  # 값 추가\n",
    "    '--alpha', '0.3',\n",
    "    '--load_model', 'None',\n",
    "    '--save_model', './saved_models/model.pth',\n",
    "    '--z_dim', '100',\n",
    "    '--gen_threshold', '0.5',\n",
    "    '--num_gen_samples', '128'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f902c",
   "metadata": {},
   "source": [
    "# 교수님 전달사항 반영\n",
    "\n",
    "1. 데이터셋을 cifar-10으로 진행할 것 --> MNIST는 너무 단순해서 GAN 성능 평가가 어려움\n",
    "2. Non-IID 환경으로 진행할 것. 이때 뒤리끌레 분포를 사용할 것\n",
    "3. GAN의 성능 향상이 필요함\n",
    "4. 데이터 세트의 수를 맞추자. unseen을 1000개 썼다면 unseen + forget도 1000개 이런 식으로!\n",
    "5. unseen 데이터와 비교해야 함. 즉 합성 데이터가 unseen 데이터와 비슷한 성능을 보이는가? \n",
    "6. 기존 연합학습에서 사용한 전체 데이터, retain 데이터, forget 데이터, 생성한 데이터 세트에 대한 분류 성능을 비교하는 걸 추가\n",
    "\n",
    "\n",
    "==> 즉, 우리는 동일한 조건에서 모든 데이터를 평가해야하고 같은 모델을 사용해야함. Unseen과 생성 데이터의 품질 격차가 적을수록 좋음! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8646d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Experiment Settings =====\n",
      "Model           : resnet\n",
      "Dataset         : cifar\n",
      "Num Clients     : 10\n",
      "Fraction        : 1.0\n",
      "IID             : 0\n",
      "Local Epochs    : 10\n",
      "Batch Size      : 64\n",
      "Learning Rate   : 0.01\n",
      "Generator z_dim : 100\n",
      "Disc. Threshold : 0.5\n",
      "===============================\n",
      "Data sizes - Forget: 4981, Unseen: 4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global Training Rounds:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Global Training Round : 1 |\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
